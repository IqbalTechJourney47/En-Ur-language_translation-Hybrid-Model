{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1b22e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets transformers[sentencepiece] sacrebleu -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfe0175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "787e8e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Iqbal\\anaconda3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import transformers\n",
    "import tensorflow as tf\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
    "from transformers import AdamWeightDecay\n",
    "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM\n",
    "from tensorflow.keras.layers import Conv1D, LSTM, Dense, Input, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb5704a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = 'Helsinki-NLP/opus-mt-en-ur'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4b3912",
   "metadata": {},
   "source": [
    "# Helsinki-NLP/opus-mt-en-ur model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deafb251",
   "metadata": {},
   "source": [
    "Source: https://huggingface.co/Helsinki-NLP/opus-mt-en-ur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5273ed",
   "metadata": {},
   "source": [
    "# The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6a201d",
   "metadata": {},
   "source": [
    "Source: https://huggingface.co/datasets/HaiderSultanArc/MT-Urdu-English/viewer/default/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba7507d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = load_dataset('HaiderSultanArc/MT-Urdu-English')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e0a77c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['en', 'ur'],\n",
       "        num_rows: 5646138\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['en', 'ur'],\n",
       "        num_rows: 1411535\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f29b795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'So, Are You In The Market?', 'ur': '\"تم یہاں بازار میں ؟\"'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db98fd26",
   "metadata": {},
   "source": [
    "# Small Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78bf5b42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['en', 'ur'],\n",
       "     num_rows: 500\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['en', 'ur'],\n",
       "     num_rows: 300\n",
       " })}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "raw_datasets = load_dataset('HaiderSultanArc/MT-Urdu-English')\n",
    "\n",
    "# Take a small subset for testing/debugging\n",
    "small_en_ur_train_dataset = raw_datasets['train'].shuffle(seed=42).select([i for i in range(500)])  # Adjust the number as needed\n",
    "small_en_ur_test_dataset = raw_datasets['test'].shuffle(seed=42).select([i for i in range(300)])  # Adjust the number as needed\n",
    "\n",
    "# Display the small datasets\n",
    "small_en_ur_dataset = {\n",
    "    \"train\": small_en_ur_train_dataset,\n",
    "    \"test\": small_en_ur_test_dataset,\n",
    "}\n",
    "\n",
    "small_en_ur_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7078307a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'And why are the kneeling on your right and on your left.',\n",
       " 'ur': '’’اور آپ ﷺ نے اپنی بائیں ہتھیلی کو بائیں ران اور گھٹنے پر رکھا۔‘‘'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_en_ur_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ed086c",
   "metadata": {},
   "source": [
    "# Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d530e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Iqbal\\anaconda3\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a116344",
   "metadata": {},
   "source": [
    "tokenizer(\"Hi, this is a sentence!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb4e9e3",
   "metadata": {},
   "source": [
    "tokenizer(\"Hi, this is a sentence!\", \"This is another sentence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b713334",
   "metadata": {},
   "source": [
    "with tokenizer.as_target_tokenizer():\n",
    "    print(tokenizer([\"Hi, this is a sentence!\", \"This is another sentence.\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d02a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 64\n",
    "max_target_length = 64\n",
    "\n",
    "source_lang = \"en\"\n",
    "target_lang = \"ur\"\n",
    "\n",
    "# Define your preprocess_function as before\n",
    "def preprocess_function(examples):\n",
    "    inputs = examples[source_lang]\n",
    "    targets = examples[target_lang]\n",
    "\n",
    "    # Tokenize inputs\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Tokenize targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "\n",
    "    # Add labels to model inputs\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "296f86b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Iqbal\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3860: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[57, 1082, 56, 3, 19626, 95, 76, 418, 7, 95, 76, 918, 5, 0], [1598, 108, 52, 82, 24319, 10376, 66, 179, 5, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[19977, 346, 88, 20669, 3292, 202, 3573, 752, 1016, 18, 132, 3032, 25058, 16, 3032, 23430, 4, 16061, 30, 12674, 17537, 0], [139, 20, 18, 257, 771, 2426, 1129, 11, 710, 1444, 8, 0]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_function(small_en_ur_dataset[\"train\"][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6332e4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 940.24 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocess_function to train and test datasets\n",
    "tokenized_train_datasets = small_en_ur_dataset[\"train\"].map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca86f5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████████| 300/300 [00:00<00:00, 2823.31 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_test_datasets = small_en_ur_dataset[\"test\"].map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2875ce9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████| 5646138/5646138 [21:11<00:00, 4441.47 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocess function to train and test datasets\n",
    "tokenized_train_datasets = raw_datasets['train'].map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8655afc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████| 1411535/1411535 [04:57<00:00, 4740.79 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_test_datasets = raw_datasets['test'].map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54382afd",
   "metadata": {},
   "source": [
    "# Hybrid Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366b3989",
   "metadata": {},
   "source": [
    "### Define CNN and RNN components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d9250a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalMaxPooling1D, RepeatVector\n",
    "\n",
    "# Define CNN and RNN components\n",
    "embedding_dim = 128\n",
    "\n",
    "#cnn_input = Input(shape=(max_input_length, embedding_dim))\n",
    "# cnn_input = Input(shape=(max_input_length, embedding_dim), name=\"input_9\")\n",
    "\n",
    "cnn_input = tf.keras.layers.Input(shape=(max_input_length, 128), name=\"cnn_input\")\n",
    "cnn_output = Conv1D(filters=64, kernel_size=3, activation='relu')(cnn_input)\n",
    "cnn_output_pooled = GlobalMaxPooling1D()(cnn_output)\n",
    "cnn_output_repeated = RepeatVector(max_input_length)(cnn_output_pooled)\n",
    "\n",
    "rnn_input = Input(shape=(max_input_length, embedding_dim))\n",
    "rnn_output = LSTM(units=64, return_sequences=True)(rnn_input)\n",
    "\n",
    "# Concatenate or combine CNN and RNN outputs\n",
    "combined_output = Concatenate()([cnn_output_repeated, rnn_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee29d051",
   "metadata": {},
   "source": [
    "# Define the final sequence-to-sequence model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1f3ec05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['’’اور آپ ﷺ نے اپنی بائیں ہتھیلی کو بائیں ران اور گھٹنے پر رکھا۔‘‘',\n",
       " 'کہا اس نے مجھے بس بد دعا سے خوف آتا ہے',\n",
       " 'ہم تجھ سے ہدایت، تقوی، عفت اور بے نیازی طلب کرتے ہیں ،',\n",
       " 'ان مثالوں سے آپ خوب سمجھ سکتے ہیں کہ خدا کی اس سلطنت میں آپ کی اصل حیثیت کیا ہے؟',\n",
       " '” آپ داستان لکھتے ہیں!',\n",
       " 'ہم ہمیشہ اس کے اس کو یاد رکھیں گے.',\n",
       " 'ذات کے گرد طوف کیے جاؤ، معلوم ہوجائے گا!',\n",
       " 'ہوجائے تو درگزر فرمائیے۔‘‘',\n",
       " 'آپ مزید زندہ نہیں رہنا چاہتیں۔',\n",
       " 'اس حوالے سے مجھے کچھ معلوم ہے۔ ‘‘ فرمایا: ’’ یَا ابْنَ اَخِیْ قُلْ وَلَا تَحْقِرْ نَفْسَكَ یعنی اے بھتیجے!',\n",
       " 'کہیں بھی، اصل مصنوعات موجود نہیں ہے.',\n",
       " '10) ان کے قلوب پر خوف الہی طاری رہتا ہے۔اللہ کے خوف کی وجہ سے ان کے بدن کپکپاتے ہیں',\n",
       " 'اسی نے آسمان و زمین کو حق کے ساتھ پیدا کیا ہے اور تمہاری صورت کو بھی انتہائی حسن بنایا ہے اور پھر اسی کی طرف سب کی بازگشت بھی ہے',\n",
       " '”حالانکہ میں تو کئی بار ان کے گھر گئی ہوں۔“',\n",
       " 'کعب کہتے ہیں ملائیکہ غضبناک ہوگئے اور جہنم زور شور سے بھڑک اٹھی ۔',\n",
       " 'Previous postسوال ہونا چاہئے',\n",
       " 'شائقین کے لئے نہیں اچھی خبر..',\n",
       " 'وعدے سب بھلا دیں وقتِ رخصت سے پہلے',\n",
       " 'بس اِک تمہیں ہو یاوَر تم پر سلام ہر دم',\n",
       " '- وتر کی تین رکعات ایک سلام کے ساتھ۔',\n",
       " 'پس اگر تمہیں کوئی جزا و سزا ملنے والی نہیں ہے۔',\n",
       " 'ترجمۂکنزُالعِرفان: اور اللّٰہ تعالیٰ نے آدم کو تمام اشیاءکے نام سکھادئیے۔',\n",
       " 'اور نہ تم اندھوں کو ان کی گمراہی سے راہ پر لاؤ، تو تم اسی کو سناتے ہو جو ہماری آیتوں پر ایمان لائے تو وہ گردن رکھے ہوئے ہیں،',\n",
       " 'اور یہ ہی امریکی کامیابی کا راز ہے\"۔',\n",
       " 'جن کے دل اللہ کے جانب ہی مائل ہوتے ہیں',\n",
       " \"بتایا جاتا ہے کہ سورابایا میں پولیس حکام نے تمام چرچز کو عارضی طور پر بند کرنے کا حکم بھی دیا ہے جب کہ شہر میں ہونے والے ایک بڑے 'فوڈ فیسٹیول' کو بھی منسوخ کر دیا گیا ہے۔\",\n",
       " 'ہمیشہ یکساں جواب دیتا ہے',\n",
       " '[جاننے کے لئے].',\n",
       " 'صدر جمہوریہ 16 دسمبر 2017 کو الہ آباد ہائی کورٹ کے ،’’ نیائے گرام ‘‘ منصوبے کا سنگ بنیادرکھیں گے ۔ بعد ازاں وہ دہلی واپس آجائیں گے۔',\n",
       " 'کیا آپ خوفزدہ ہونے کے خوف سے ڈرتے ہیں؟ تم اس پر کھڑے ہو',\n",
       " 'ان کا کہنا تھا کہ \"اس بات کی کوئی وجہ نہیں ہو سکتی اس برائی کے نمونے سے کوئی مذاکرات نہیں ہوں گے۔ اس طرح کے قاتل صرف طاقت کی زبان سمجھتے ہیں۔ لہذا امریکہ اپنے اتحادیوں کے ساتھ مل کر موت کے اس نیٹ ورک کو ختم کرنے کے لیے کام کرے گا۔\"',\n",
       " 'ظاہر ہے كہ نہ تو خدا كا فرمان غلط ہوسكتا ہے نہ ہی خدا كا كلام جھوٹ ہوسكتا ہے،',\n",
       " 'کیا الله کے دین کے سوا کوئی اور دین تلاش کرتے ہیں حالانکہ جو کوئی آسمان اور زمین میں ہے خوشی سے یا لاچاری سے سب اسی کے تابع ہے اور اسی کی طرف لوٹائے جائیں گے',\n",
       " 'آپ کے ساتھ موسیقی لے لو، جہاں بھی تم جاؤ.',\n",
       " '” تو ان سے مزدوری مانگتا ہے پھر یہ اس تاوان کے بوجھ سے دبے جاتے ہیں۔”',\n",
       " 'ماں تو جیسے بے وقوف ٹھیری۔‘‘',\n",
       " 'خیر یہ ایسا زندگی اور موت کا مسلہ بھی نہیں تھا سو سرکا دیا خود کو ایک طرف”',\n",
       " '” نہیں اب میں زندہ نہیں رہنا چاہتا”',\n",
       " 'بغاوت کے الزام میں گرفتار ہونے والے آٹھ ہزار کشمیری ابھی تک لاپتہ ہیں',\n",
       " 'کیا آپ اس کھلاڑی کو پہچانتے ہیں',\n",
       " 'یہ ٹھونسنے کے الفاظ صرف ایک ہی اندھے کے لیے تھے.',\n",
       " 'ایک نوجوان نے مجھے پیٹا اس وجہ سے میں نے اسے قتل کر دیا۔',\n",
       " 'قیس بن کثیر کہتے ہیں کہ',\n",
       " 'انہیں ذروں کو لیکن ہم ستارہ کرتے رہتے ہیں',\n",
       " 'یقینا اس میں بھی ایک نشانی ہے لیکن ان میں سے اکثر ایمان نہیں لاتے۔',\n",
       " '\\u202bکے قلعۂ مبارک میں جلوس فرماتے ہیں۔ ُان دنوں دو چار مہینے سے\\u202c',\n",
       " 'اگر وہ تم سے مال طلب کرے اور تمہیں تنگ کرے تو تم بخل کرنے لگو اور وہ (بخل) تمہاری بدنیتی ظاہر کرکے رہے',\n",
       " 'آپ کی کہانی -',\n",
       " 'مجھ سے دل مانگے تو انکار کروں یا نہ کروں',\n",
       " '”کوئی پختون تو نہیں گاڑی میں؟“',\n",
       " 'بجز اس کی بیوی کے اس کی نسبت ہم نے یہ طے کیا ہے کہ وہ پیچھے رہ جانے والوں میں سے ہوگی۔',\n",
       " 'یہ سب راتوں رات نہیں ہوگا',\n",
       " '-اچھا.',\n",
       " 'اس طرح وہ جوان عورتوں کو تعلیم دیں کہ وہ اپنے شوہروں سے اور بچوں سے محبت کریں۔',\n",
       " 'سو جو لوگ بدبخت ہوں گے (وہ) دوزخ میں (پڑے) ہوں گے ان کے مقدر میں وہاں چیخنا اور چلّانا ہوگا،',\n",
       " 'اور اگر ہم نے رسول سے پہلے انہیں عذاب کرکے ہلاک کردیا ہوتا تو یہ کہتے پروردگار تو نے ہماری طرف رسول کیوں نہیں بھیجا کہ ہم ذلیل اور رسوا ہونے سے پہلے ہی تیری نشانیوں کا اتباع کرلیتے',\n",
       " 'اور ان کے رب نے ان کو پکارا کیا میں نے تم دونوں کو اس درخت سے منع نہ کر چکا تھا اور یہ نہ کہہ چکا کہ شیطان تمہارا صریح دشمن ہے ،',\n",
       " 'لیکن انتظار کیجیے, ہم آپ کے لئے زیادہ بری خبر ہے.',\n",
       " 'میں تری آرزو میں زندہ ہوں',\n",
       " 'حضرت ابوہریرہ سے روایت ہے کہ رسول اکرم ﷺ نے فرمایا کسی بندہ کے لیے مناسب نہیں کہ وہ یہ کہے کہ میں یونس سے بہتر ہوں(متفق علیہ)',\n",
       " 'ajeerya کے انگریزی معنی from time to time',\n",
       " 'اضافی معلومات اپنے پروفائل میں شامل کیا جا سکتا',\n",
       " '’’میں مراد ہوں۔۔۔ اور میں ہر اس شخص سے لڑوں گا، جو دوسروں کو تکلیف دیتا ہے۔۔۔‘‘',\n",
       " 'امیرالمؤمنین(ع) کی رجعت اور شیطان کی موت',\n",
       " 'لیکن یہ قوت، طاقت، وہاں بن رہا ہے!',\n",
       " 'عراق اور شام میں دیگر حالیہ حملوں میں، اس گروہ نے کم معیار کی تصاویر پوسٹ کیں، جو گزشتہ برسوں کی ہائی ٹیک پوسٹنگ سے کوسوں دور ہیں۔',\n",
       " 'کثرت ازدواج معاملہ زیادہ اہمیت کا حامل ہے یا...',\n",
       " 'میں لوگوں کی دیکھ بھال نہیں کرتا ، جو میری دیکھ بھال نہیں کرتا ہے۔',\n",
       " 'شام مسکراتی ہے',\n",
       " '’’تم میں سے کوئی شخص یہ دعا نہ کرے: اللَّهُمَّ اغْفِرْ لِي إِنْ شِئْتَ ، اللَّهُمَّ ارْحَمْنِي إِنْ شِئْتَ ( اے اللہ!',\n",
       " 'اب آپ بتاؤ کہ آپ سچے ہو یا آپ کا مرزا قادیانی؟؟',\n",
       " 'اپنی آمدنی کو ذیل کے حصوں میں تقسیم کریں ۔',\n",
       " '‘‘ان کے نعرے اور ظاہری باتیں دوسرے لوگوں سے اچھی ہوں گی اور متاثر کرنے والی ہوں گی۔’’',\n",
       " 'یہی وجہ ہے کہ ہابس ہے!',\n",
       " 'اللہ سچ کرے کہیں جھوٹی خبر نہ ہو',\n",
       " 'اگر چارج کی بجلی کی ممکنہ تبدیلی # 21 ج # سے # 17 ج # میں ہوتی ہے تو، پوائنٹس A اور B کے درمیان وولٹیج کیا ہے؟',\n",
       " '’’ اوریوں ہوگا کہ اگر وہ تیرا یقین نہ کریں اور پہلے معجزہ ( یعنی لاٹھی کے سانپ بن جانے )کے معجزہ کو بھی نہ مانے تو وہ دوسرے معجزہ (یعنی ہاتھ کی سفید ی اور چمک )کے سبب سے یقین کریں گے ۔‘‘ (خروج باب۴ آیت ۸)',\n",
       " 'وه کہے گا کہ کاش کہ میں نے اپنی اس زندگی کے لئے کچھ پیشگی سامان کیا ہوتا',\n",
       " 'The cardinal number that is the sum of seventeen & oneاٹھارہ گنتی کا ایک عدد',\n",
       " 'ارے.',\n",
       " 'ترجمہ: پس اپنے دلوں کو اللہ کے ذکر سے مطمئن کرو (تسلی دو)۔',\n",
       " 'کیا آپ جانتے ہیں اللہ تعالی آپ کیلئے کون سے غیر متوقع خوبصورت اشیاء (اسباب) تخلیق کرتا ہے بے شک اللہ تعالی کے نزدیک دین اسلام ہی ہے',\n",
       " 'بہت گندہ کام کیا ہے تم نے اس کے ساتھ۔‘‘',\n",
       " 'کوئ کتنی بھی نا انصافی کر لے آخر میں فیصلہ تو رب کی ذات نے ہی کرنا ہے',\n",
       " 'سٹون نے کہا کہ ایک اور شخص جو فرانسیسی تھا اور جس کا نام ظاہر نہیں کیا گیا ’’بہت تعریف کا مستحق ہے‘‘ کیونکہ وہ پہلا شخص تھا جس نے مسلح شخص کو روکنے کی کوشش کی۔',\n",
       " 'دمشق یونیورسٹی کے',\n",
       " 'جیسے کہ میں الفاظ so cool کا بہت استعمال کرتا ہوں.',\n",
       " 'یہ بھی پڑھیں: اخبار کا رنگ پیلا پڑ جا نے کی وجہ جانیئے',\n",
       " 'سائنس اور ٹیکنالوجی کی وزارت مرکزی کابینہ نے بھارت اور تھائی لینڈ کے درمیان فلک شناسی کے شعبے میں مفاہمت نامے پر دستخط کی منظوری دےدی ہے اس مفاہمت نامے سے اضافہ شدہ سائنسی رابطے اور تربیت نیز سائنسی ڈھانچے وغیر ہ کے مشترکہ استعمال کے ذریعہ انسانی وسائل کے فروغ اور نئے سائنسی نتائج کے حصول میں مدد ملے گی۔',\n",
       " '” اپنے رب کو خوف اور امید سے پکارتے ہیں “۔',\n",
       " 'کیا تم یہ خیال کرتے ہو کہ ہم نے تم کو بےفائدہ پیدا کیا ہے اور یہ تم ہماری طرف لوٹ کر نہیں آؤ گے؟',\n",
       " 'یہ دہنی طرف والے ہیں',\n",
       " 'شارجہ: اماراتی شہری نے اپنے والد کو آگ بجھانے والے آلے سے قتل کر دیا',\n",
       " 'احکام ۵ — تم اپنے والدین کی عزت کرنا تاکہ تمہاری عمر اُس ملک میں دراز ہوجوتمہارے پروردگار نے تمہیں عطا کیا ہے۔',\n",
       " 'جس پیمانے پر اور جس کامیابی کے ساتھ کھیلوں انڈیا یوتھ گیمس کا انعقاد ہوا ہے اس پر خوشی کا اظہار کرتے ہوئے شیٹی نے کہا کہ یہ ناقابل یقین ہے کہ اتنے سارے نوجوانوں کو یہ محسوس کرنے کا موقع مل رہا ہے کہ وہ کل کے اسٹار ہیں۔',\n",
       " 'یہ قرآن کی مندرجہ ذیل آیت میں مراد ہے: \".',\n",
       " 'مثال کے طور پر, ہر شادی biodata ایک تصویر حاصل کرنے کی توقع کی جاتی ہے, کے بارے میں وضاحت اپنے آپ کو اور اپکا توقعات, ایک مختصر لکھیں آپ کے خاندان کے بارے میں, آپ کے تعلیمی اور پیشہ ورانہ پس منظر اور آپ کے طرز زندگی اور مفادات.',\n",
       " 'وہی خدا ہے جس کے سوا کوئی معبود نہیں۔ پوشیدہ اور ظاہر کا جاننے والا ہے وہ بڑا مہربان نہایت رحم والا ہے',\n",
       " 'ہم باغ میں آدم کے بارے میں سوچ کر سکتے ہیں.',\n",
       " 'محشر سے کم نہیں ہے ساجن شباب تیرا',\n",
       " '(آخری اپ ڈیٹ 25.04.2018کو)',\n",
       " 'جانتے ہو تمہیں مشکل میں ڈالنے سے پہلے',\n",
       " 'کسی جانب سے کوئی نعرۂ یاہو آئے',\n",
       " '5:15 اے کتاب والو (ف۵۴) بیشک تمہارے پاس ہمارے یہ رسول (ف۵۵) تشریف لائے کہ تم پر ظاہر فرماتے ہیں بہت سی وہ چیزیں جو تم نے کتاب میں چھپا ڈالی تھیں (ف۵۶) اور بہت سی معاف فرماتے ہیں (ف۵۷) بیشک تمہارے پاس اللہ کی طرف سے ایک نور آیا (ف۵۸) اور روشن کتاب(ف۵۹)',\n",
       " 'الله تعالیٰ ان سے محبت کرتا ہے',\n",
       " 'غائب کرنا کے انگریزی معنی make away withremove stealthily',\n",
       " 'اُس کی شراب ِ ناب سے بڑھ کر ہے، چشمِ مست',\n",
       " 'تصویر کے کاپی رائٹ SNOW LEOPARD TRUST',\n",
       " '9 زندگی کے ساتھ جھومتی گاتی ہے غزل .',\n",
       " 'اصلیت واضح ہوتی ہے تو ہم ان پر برہم ہوتے ہیں یا کبھی انہیں دھتکار بھی دیتے ہیں۔ پھر ہم کسی اور',\n",
       " 'این ایس سی سی کولکاتا ایس ٹی سی کٹک ایس ٹی سی پٹنہ ایس ٹی سی جلپائی گوڑی ایس ٹی سی ہزاری باغ ایس ٹی سی اگرتلہ ایس ٹی سی سندر گڑھ ایس ٹی سی رانچی 2.',\n",
       " '\" نہ ان کے گوشت اللہ کو پہنچتے ہیں نہ خون مگر اسے تمہارا تقوی پہنچتا ہے۔(22-37)',\n",
       " 'تاکہ وصلِ حق کی مل جائے خبر',\n",
       " 'بائنری کے اختیارات ٹریڈنگ سے فائدہ اٹھانا.',\n",
       " 'ایک سے زیادہ ہے \"آپ\"',\n",
       " '20 ہمارے خدا اور باپ کا جلال ہمیشہ ہمیشہ کے لئے رہے آمین۔',\n",
       " 'پیامبر اکرم (صلی اللہ علیہ و آلہ و سلم) فرماتے ہیں: روزہ جہنم کی آگ کے مقابلے میں سپر ہے\"۔',\n",
       " 'پوری خبر دیکھیے:',\n",
       " 'یہاں آپ کے لئے تھوڑا سا تاریخ سبق ہے.',\n",
       " 'صاحبو، تاریخ آپ کو معاف نہیں کرے گی',\n",
       " 'وہ دستک بھی تمہاری سُن رہا ہے',\n",
       " 'جہادسے پیچھے رہنے کی اجازت؟',\n",
       " 'وہ آپ کے سر میں چھوٹے آواز amplify.',\n",
       " 'جو میری پیروی کرتا ہے وہ اندھیرے سے نکلتا ہے (رات سے باہر نہیں بلکہ بے خبر ہے) اور روشنی کی طرف چل جائے گا.',\n",
       " 'اور (یہ منافق لوگ) جب اہل ایمان سے ملتے ہیں تو کہتے ہیں ہم بھی ایمان لائے ہیں اور جب آپس میں تنہا ہوتے ہیں تو کہتے ہیں کہ کیا تم ان (مسلمانوں) کو وہ باتیں بتاتے ہو جو اللہ نے (توراۃ میں) تم پر ظاہر کی ہیں۔ تاکہ وہ انہیں تمہارے پروردگار کے حضور تمہارے خلاف بطور حجت پیش کریں۔ کیا تم عقل سے کام نہیں لیتے۔',\n",
       " 'ذلّت کے وہ لمحات دنیا کے سامنے آگئے!',\n",
       " 'یہ طویل ٹرین سواری ناپسند کرتا ہے جو کسی بھی بہادر کے لئے یہ بہترین راستے کا ہوتا ہے.',\n",
       " '58 افراد زخمی ہوئے ہیں.',\n",
       " 'خدا لا ریب واحد ہے، وہ یکتا بے گماں ہے',\n",
       " 'کہاں ہیں وہ خوبصورت چہرے ؟',\n",
       " 'ایک مرتبہ جب یہ عمل مکمل ہوجاتا ہے تو حکومت مرکزی، ریاستی یا میونسپل، مناسب سطح پر مزید بہتری لائی جاسکتی ہے۔',\n",
       " 'باتیں کرو ایسی کہ وہ بیمار بہل جائے',\n",
       " '(اللہ) گرفت کرے گا اس پر جو تمہارے دلوں نے کیا ہو گا۔“',\n",
       " 'یہ جیل، خودکش نظریے اور مختلف صحت کے مسائل کا وقت بن سکتا ہے.',\n",
       " 'الف دل میں ہنسا :۔ (عقل کی اندھی !',\n",
       " 'اسی طرح اگر اس کو بے دریغ استعمال کیا جائے تو جگر پر بھی اس کے منفی اثرات مرتب ہوتے ہیں ۔',\n",
       " 'آپ یا آپ کے بچے',\n",
       " 'Coolordrool کا پہلا بلاگ!',\n",
       " 'امکان ہے کہ عالمی سلامتی کونسل کے اکثر رکن ملک اس قرارداد کی حمایت کریں گے',\n",
       " 'اسم نکرہ ( مذکر - واحد ) ١ - اونچے گھرانے کا، عزت والا، امیر زادہ۔',\n",
       " 'تبصرے پر Adobe Shockwave Player',\n",
       " 'اﷲ عزوجل نے سیدنا آدم علیہ السلام کو مٹی کی ایک مٹھی سے پیدا فرمایا۔',\n",
       " '۶۸:۱۸:اور انشاء اللہ نہیں کہیں گے',\n",
       " 'یقیناً ہمارے ہاں سخت بیڑیاں ہیں اور سلگتی ہوئی جہنم ہے',\n",
       " 'ہی جنّت الماو ٰی ہےجب کے اسوقت سدرہ ة پرچھا رہا تھا جو چھا رہا تھا',\n",
       " '’’اللہ کی بندیوں کو مت مارا کرو۔‘‘',\n",
       " 'الیکشن کمیشن کے مطابق کاغذات نامزدگی 24 جولائی کو جمع کرائے جائیں گے۔',\n",
       " '8) کیا پلٹ کر بچشم تر دیکھا',\n",
       " 'اگر آپ دنیا کے بارے میں تبدیل کرنے کے لئے صرف ایک چیز منتخب کرسکتے، تو وہ کیا ہو گی؟',\n",
       " 'گھوٹالہ گردہ گڑ',\n",
       " '38 جب وہ کھا کر سیر ہوئے تو گیہوں کو سمندر میں پھینک کر جہاز کو ہلکا کرنے لگے۔',\n",
       " 'مجھے مغزیات سے الرجی ہے Sou alérgico a nozes',\n",
       " 'بچہ رہتا ہے',\n",
       " 'جب زمین پھٹتی ہے آتا ہے سمندر میں اُبال تب تو فرعون بھی اقرارِ خدا کرتے ہیں',\n",
       " 'وہ وقت کا جہاز تھا ، کرتا لحاظ کیا',\n",
       " 'میں آکسٹرا کے سبھی موسیقی کاروں ، نگراں ، وشوسبارمن اوربانیان ، نرپمااور سدھاررواو کو جنوب ایشیائی خطے میں امن اور انسانیت پرست اور تعاون کو بڑھاوادینے کی کوششوں کے لئے اپنی نیک تمناوں پیش کرتاہوں ۔',\n",
       " 'کس قدر حسرتناک ہے ان بندوں کا حال کہ جب ان کے پاس کوئی رسول آتا ہے تو اس کا مذاق اُڑانے لگتے ہیں',\n",
       " '(1) اس دینی تربیت کا آغاز بچے کی ولادت سے ہی ہوجاتا ہے، جب پیدائش کے بعد اس کے کان میں اذان دی جاتی ہے، حدیث ِنبوی ہے کہ',\n",
       " '\\u202bلگوائیں جبکہ مسئلہ یہ ہے کہ ایک لفظ سے اگر کوئی پوری قوم پر تہمت لگائے تو\\u202c',\n",
       " 'شاہد خاقان عباسی نے چیئرمین نیب کی تقرری پر قوم سے معافی مانگتے ہوئے کہا کہ نیب کا ادارہ ہی غلط ہے',\n",
       " 'ترجمۂ کنزالایمان: اور عورت سے یوں سزا ٹل جائے گی کہ وہ اللّٰہ کا نام لے کر چار بار گواہی دے کہ مرد جھوٹا ہے (ف۱۳)',\n",
       " 'وہ ان کے دلوں پر ایک کوچ ہے کیونکہ آپ نہ ان کو تحریری طور پر کچھ بھی دکھا سکتے ہیں.',\n",
       " '10 ۔ پروردگار عالم کی حقیقت سب کے لیے پوشیدہ ہے۔',\n",
       " \"باقی سب اچھا ہے سر !''\",\n",
       " 'انہوں نے کہا کہ میں تمام کے بہادر تھااس دن. \"',\n",
       " 'وزارت اور حج کمیٹی آف انڈیا کی طر ف سے سینئر افسروں کی ایک ٹیم نے مختلف سہولتوں کا جائزہ لینے کے لئے حال ہی میں سعودی عرب کا دورہ کیا تھا۔',\n",
       " '“ہے تو نہیں۔لادوں گا۔ کیا لیں گے آپ؟”',\n",
       " 'آپ کا پیغام 20-8000 حروف کے درمیان ہونا چاہئے',\n",
       " 'بوب ڈیلن قرطبہ میں ایک کنسرٹ کے دوران',\n",
       " 'کس سے پوچھوں کہ کہاں گم ہوں برسوں سے',\n",
       " 'تو مت ڈر کیونکہ میں تیرے ساتھ ہوں۔ ہراسان نہ ہو کیونکہ میں تیرا خدا ہوں میں تجھے زوربخشونگا۔ میں یقیناً تیری مدد کرونگا اور میں اپنی صداقت کے دہنے ہاتھسے تجھے سنبھالونگا۔',\n",
       " 'اﷲ چاہتا ہے توکل والوں کو۔',\n",
       " 'اور ہر شاعر کو اپنا کلام عزیز ہوتا ہے۔ اس کے لئے اپنے پورے کلام میں سے بہتر',\n",
       " 'سانول بھیجنے والے تیرا نام ہے سچ',\n",
       " 'مستقبل مسلمانوں کا ہے',\n",
       " '40 اور انہوں نے ہارون سے کہا کہ ہمارے لئے اَیسے معبود بنا جو ہمارے آگے آگے چلیں کیونکہ یہ موسیٰ جو ہمیں ملک مصر سے نکال لایا ہم نہیں جانتے کہ وہ کیا ہوا۔',\n",
       " 'کی طرف سے Mr. T',\n",
       " 'i۔انٹرنیشنل لیبر آرگنائزیشن (آئی ایل او) کا انٹرنیشنل ٹریننگ سینٹر آئی پی سی 1964 میں ٹورن میں قائم ہوا تھا۔',\n",
       " 'جب ان سے کہا جاتا ہے کہ دوسرے مومنین کی طرح ایمان لے آؤ تو کہتے ہیں کہ ہم بے وقوفوں کی طرح ایمان اختیار کرلیں حالانکہ اصل میں یہی بے وقوف ہیں اور انہیں اس کی واقفیت بھی نہیں ہے',\n",
       " 'یہ اب بھی ایک فرانسیسی جگہ ہے!',\n",
       " 'کشمیریوں پر بڑا ظلم ہو رہا ہے۔ اللہ انکی مدد کرے۔\" \" ماما!',\n",
       " 'تجزیہ آپ کو اپنے عنوان کو بہتر بنانے میں مدد ملے گی اگر یہ بہت کمزور ہے (50 سکور سے نیچے).',\n",
       " 'میں اپنے بچوں سے بات کرتا ہوں جو حقیقی دنیا میں ہوتا ہے.',\n",
       " 'غلطی کو میں نے اکاؤنٹ میں نہیں لے پیشن ذکر کیا ہے کہ دو مرتبہ ساڑھے تین سال کی طرف سے بنا دیا لگتا ہے.',\n",
       " '\"یہ نام چینی تو نہیں لگتا!!!”',\n",
       " 'ڈالر کی بڑھتی قدر، افغانوں کی مشکلات بڑھاتی ہوئی',\n",
       " 'ان کے لیے وہاں میوہ ہوگا اور انہیں ملے گا جو وہ مانگیں گے',\n",
       " 'یا وہ کوئی چال چلنا چاہتے ہیں؟ تو جو لوگ کافر ہیں وہ خود اپنی چال کا شکار ہیں۔',\n",
       " '19 جو اس سے ڈرتے ہیں وہ ان کی مراد پوری کرے گا۔ اور ان کی فریاد سنے گا اور ان کو بچا لے گا۔',\n",
       " 'خبر کے سامنے پر رپورٹ کرنے کے لئے بہت زیادہ مادہ نہیں ہے.',\n",
       " '17 وہ چلتے وقت اپنے چاروں پہلوﺅں پر چلتے تھے اور پیچھے نہیں مڑتے تھے۔',\n",
       " 'والے اے زندوں کو موت دینے والے اے وہ زندہ کہ تیرے سوا کوئی معبود نہیں اے معبود ہمارے مولا امام',\n",
       " 'ٹاملناڈو کی 3000سے زائد مساجد میں رمضان کے دوران 4900ٹن چاول کی سربراہی',\n",
       " 'جب آئے کانوں میں صدا محمد رسول اللہ',\n",
       " '؟؟ کچھ ہوا؟؟',\n",
       " 'یہ سچ ہے ترے ہجر کی اُفتاد سے پہلے',\n",
       " 'کیا میرا رب مجھے بھی معاف کردے گا !',\n",
       " 'یہاں تک جنات کی گفتگو ختم ہوگئی۔',\n",
       " 'تاہم وہ کہتے ہیں کہ انھوں نے اپنی تحقیق میں دوسرے تمام عوامل کا خیال رکھا تھا۔',\n",
       " 'اس دورے کے دوران ہم لوگ اپنے باہمی تعلقات خصوصاً تعاون میں اضافہ کرنے اور میانمار میں بھارت کی جانب سے دی جارہی سماجی۔ اقتصادی امداد کے مختلف پہلوؤں پر نظر ثانی کریں گے اور ان دیگر نئے شعبوں کی تلاش کریں گے جن میں ہم دونوں ممالک مستقبل میں مل کر کام کرسکتے ہیں۔',\n",
       " '۶۔جب وہ اس کے کناروں پر بیٹھے تھےo',\n",
       " 'کیا سمجھے خورشید احمد بھائی ؟ آپ میں ہمت ہو مجھ میں تو نہیں !',\n",
       " 'یقیناً ہم نے آسمانوں اور زمین اور جو کچھ اس کے درمیان ہے سب کو (صرف) چھ دن میں پیدا کر دیا اور ہمیں تکان نے چھوا تک نہیں',\n",
       " \"یہاں ایک مختصر 'شروعات' فہرست ہے۔\",\n",
       " 'نیٹا کے انگریزی معنی mucus of the nose',\n",
       " 'چلو اک دوسرے کو بھول جائیں',\n",
       " 'مگر ہائے اقتدار کی شراب!',\n",
       " 'جس نے انہیں بھوک میں کھانا دیا، اور انہیں ایک بڑے خوف سے امان بخشا',\n",
       " 'تبصرے پر GPU-Z',\n",
       " '(46) مال اور بیٹے تو دنیا کی زندگی کی (رونق و) زینت ہیں۔ اور نیکیاں جو باقی رہنے والی ہیں وہ ثواب کے لحاظ سے تمہارے پروردگار کے ہاں بہت اچھی اور امید کے لحاظ سے بہت بہتر ہیں',\n",
       " 'تکبر تدبر کو کھا جاتا ہے اور حد سے زیادہ اعتماد بہا لے جاتا ہے',\n",
       " '’کسی نے بھی یہ نہیں کہا کہ جرم ہوا ہے‘',\n",
       " 'مجھے خود پر بے حد یقین تھا….',\n",
       " 'یرغمال کرنے والوں باہر نکلنے کے لیے ایک محفوظ راستہ فراہم کیا جائے۔',\n",
       " 'اور یہ کہ جو لوگ آخرت کو نہیں مانتے، ان کے لئے ہم نے ایک درد ناک عذاب تیار کر رکھا ہے۔(10)',\n",
       " 'یہ اس لئے کہ انہوں نے اللہ اور اس کے رسول (صلی اللہ علیہ وآلہ وسلم) کی مخالفت کی، اور جو شخص اللہ اور اس کے رسول (صلی اللہ علیہ وآلہ وسلم) کی مخالفت کرے تو بیشک اللہ (اسے) سخت عذاب دینے والا ہے،',\n",
       " 'اب \"آسمان سے زمین سے.\"',\n",
       " 'جس روز اس کا اخیر نتیجہ پہنچ آئے گا اس روز وہ لوگ اس کو پہلے سے بھولے ہوئے تھے یوں کہیں گے کہ واقعی ہمارے رب کے پیغمبر سچی سچی باتیں لائے تھے سو اب کیا کوئی ہمارا سفارشی ہے کہ ہماری سفارش کر دے یا کیا ہم پھر واپس بھیجے جاسکتے ہیں تاکہ ہم لوگ ان اعمال کے جو ہم کیا کرتے تھے برخلاف دوسرے اعمال کریں اور آیت میں ہے:',\n",
       " 'مجھ سے ملے تو اور بھی وہ خوش نما ہوئے',\n",
       " 'م ن۔ح ا۔ع ج : 4981',\n",
       " '\"دھوتا ہوں جب میں پینے کو اس سیم تن کے پاؤں\"',\n",
       " 'اللہ تعالیٰ کا ارشاد ہے : مرد عورتوں پر قوام ہیں۔',\n",
       " 'میرے کمرے میں کتابوں کے سوا کچھ بھی نہیں \\u200b',\n",
       " '5- اس میں 114 سورتیں ہیں۔',\n",
       " 'وہ مرجائے گی',\n",
       " 'ان کے علاوہ اور بھی قرائن و شواہد ہوسکتے ہیں جن کی تفصیل کی اس وقت ضرورت نہیں ہے۔',\n",
       " 'ہم جنس پرستوں کے خلاف امتیازی سلوک کی مذمت',\n",
       " 'A friend loveth at all times, and a brother is born for adversity.Proverbs 17:17دَوست ہر وقت مُحبّت دِکھاتا ہے اور بھائی مُصِیبت کے دِن کے لِئے پَیدا ہوتا ہے۔امثال 17:17',\n",
       " 'تم پر سلام ہو تم نے جو کچھ کیا عمدہ کیا) کے الفاظ سے ہاتھ سے ہاتھ ملا کر انسان',\n",
       " 'معلوم نہیں کیوں کہ خواب بلیک اینڈ وائٹ تھا۔',\n",
       " 'کیا آپ جانتے ہیں کہ یہ عظیم بطل کون تھے؟',\n",
       " 'جمعہ مبارک کہنا بدعت ہے یا نہیں؟',\n",
       " 'لگتا تھا کہ وہ کچھ پینے آئے ہیں۔',\n",
       " 'Please شامل میں us!',\n",
       " 'دروازہ بہشت کی کنجی ہے نماز',\n",
       " '\\u200fملک کا مستقبل نوجوانوں سے ہے',\n",
       " 'روشنی سےڈرتےہو؟',\n",
       " 'ریاستوں کی سرگرم حمایت سے جل شکتی مشن کی رہنمائی کر رہی ہے جس کے ذریعے دیہی لوگوں کی زندگی میں خوشیاں لائی جاسکیں۔ اور یہ کام باضابطہ اور طویل مدتی بنیاد پر وافر مقدار میں اور متعلقہ معیار کا پینے کا پانی فراہم کرکے کیا جارہا ہے۔',\n",
       " '14 پھر یوسف نے اپنے باپ یعقوب اور سارے کنبے کو جو پچھّتر جانیں تھیں بلا بھیجا۔',\n",
       " 'کیا صحت کارڈ بنانے کیلئے کسی کو سفارش کرنے یا کسی کو پیسے دینے کی ضرورت ہیں؟',\n",
       " 'اللہ سےمعافی؟ \"نہیں\"',\n",
       " 'ترکی کے مشہور انگریزی اخبار(Daily Sabah)',\n",
       " 'بس آپ کے طور پر, باپ, مجھ میں ہو, اور میں تم میں ہوں, تو بھی وہ امریکہ میں ایک ہو سکتا ہے: تا کہ دنیا کہ تم نے مجھے بھیجا ہے ایمان لاؤ.',\n",
       " 'پیٹ کمنز کے شاہینوں پر وار',\n",
       " '”تمہیں کچھ یاد آرہا ہے؟“',\n",
       " 'بالیقین خواہ تم مر جاؤ یا مار ڈالے جاؤ جمع تو اللہ تعالیٰ کی طرف ہی کئے جاؤ گے۔',\n",
       " 'آپ اپنے گھر کے لئے ایک مخصوص نظر شامل کرنے کے لئے تیار ہیں؟',\n",
       " 'عربی کے لفظ تَعْلُو نے پوری بات کھول دی .',\n",
       " 'ایک ہفتے کے بعد وہ لوگ جو فیس بُک استعمال نہیں کر رہے تھے، ان کا کہنا تھا کہ وہ اپنی زندگیوں سے زیادہ مطمئن ہیں۔',\n",
       " '’’مول چند کے باغ میں ہے وہ۔‘‘',\n",
       " 'وزیراعظم کا دفتر وزیراعظم نے، شمال مشرقی خطے کے حُسن اور خوبصورتی کی ستائش کی خوبصورت شمال مشرقی خطے کی سیاحت کے فوٹو شئیر کئے جانے چاہئیں ،وزیراعظم کی گزارش نئیدہلی08فروری۔وزیراعظم نریندر مودی نے شمال مشرقی خطے کی زبردست خوبصورتی کی تعریف کی ہے ۔',\n",
       " 'تختوں پر تکیہ لگائے ہوئے جو قطاروں میں بچھے ہوئے ہیں اور ہم ان کا نکاح بڑی بڑی آنکھوں والی حوروں سے کر دیں گے',\n",
       " 'بعد بہت سے دوسرے فنکاروں نے اپنا کام دکھایا اور آرٹ میں نئی اور مختلف تخلیقات سامنے آئیں۔',\n",
       " 'ایکویریم پانی میں اور کے تحت زندگی کی ایک مکمل حسی اور captivating تجربہ فراہم کرتا ہے.',\n",
       " 'اور جنہوں نے کفر کیا (ان سے کہا جائے گا) کیا میری آیات تمہیں سنائی نہیں جاتی تھیں؟ پھر تم نے تکبر کیا اور تم مجرم قوم تھے۔',\n",
       " '’’تم نے ایک بیس پوڑیاں کھائی ہوں گی؟‘‘',\n",
       " 'اور ہر شیطان سرکش سے اس کو محفوظ کر دیا ہے',\n",
       " 'پوشیدہ اور ظاہر کا جاننے والا غالب اور حکمت والا ہے',\n",
       " 'دو گروپوں میں تصادم',\n",
       " 'اپنی سب راہوں میں اُسکو پہچان اور وہ تیری راہنمائی کریگا ۔',\n",
       " 'اس آرٹیکل میں ہم آپ کو مصنوعات کے بارے میں مزید بتانا چاہتے ہیں.',\n",
       " 'واقعی یہ لوگ جہاد کے لئے نکلنے کا ارادہ رکھتے تو اس کے لئے ضروری تھا کہ کچھ',\n",
       " 'نے وعدہ کیا تھا کہ ہم سے واپس جانے کا کرایہ نہیں لیا جائے گا، مگر یہ دوسری بس',\n",
       " '2 ۔ یہ فوڈ ایڈیٹِوز کے طور پر استعمال کیا جا سکتا ہیں، نہ صرف رنگ، خوشبو اور ذائقہ بہتر ہیں لیکن خوراک کی غذائیت قدر کو بہتر بنانے.',\n",
       " '16 کوئی بھی شخص چراغ جلا کر اس کو کسی برتن کے اندر یا کسی پلنگ کے نیچے چھپا کر نہیں رکھتا حالانکہ گھر میں آنے والوں کو روشنی فراہم کرنے کے لئے وہ اس کو شمعدان پر رکھتا ہے۔',\n",
       " 'بے جا ہے بادشاہی ہر خوب رو کوں دینا',\n",
       " 'بلاشبہ ہم نے تمہیں ایک مرد اور ایک عورت سے پیدا کیا ہے۔“',\n",
       " 'الله کا عذاب اترتا ہے',\n",
       " 'معمولی تھا کہ چار صحابہ تو خود ہی دستبردار ہو گئے جس سے ان کی بے غرضی کا اندازہ',\n",
       " 'عجیب سفر تھا … ..',\n",
       " 'ُٰٰٰٰوہ مختصر مگر بہت اعلی بات کرتے ہیں .',\n",
       " 'اے میرے رب نہیں.. \"',\n",
       " 'اسحاق بھائی کیا آپ نے نام تبدیل کروالیا',\n",
       " 's سیکنڈ کرنا Milliseconds ms',\n",
       " 'میں تو ہں وہی جو پہلے تھا تیرے لیے',\n",
       " 'شفا کے معنی',\n",
       " 'ترکی میں \"تمام شامل\"',\n",
       " '5.3 مزید تحقیقات کے لئے تجاویز (Suggestions for Further Researches)',\n",
       " 'آپ کھاتے ہیں جب آپ بھوکا نہیں ہیں',\n",
       " 'جس دن سب رب العالمین کی بارگاہ میں حاضر ہوں گے',\n",
       " 'بتاؤ) اگر تم سچے ہو،',\n",
       " '’’ اللہ تعالیٰ کے بندوں میں صرف علم رکھنے والے لوگ ہی اللہ سے ڈرتے ہیں‘‘(سورۃ الفاطر:28)خوف خدا مومنین کی نشانی ہے :',\n",
       " 'پس جان لو کہ اللہ ہی تمہارا مولیٰ ہے',\n",
       " '(Greek mythology) a river in Hades across which Charon carried dead soulsدوذخ کے پانچ دریاٴوں میں سے کوئی ایک ، دریائے دوذخ',\n",
       " 'کہاتمہارا کیا واقعہ تھا جب تم نے یوسف کو پھسلایا تھا انہوں نے کہا الله پاک ہے ہمیں اس میں کوئی برائی معلوم نہیں ہوئی عزیز کی عورت بولی اب سچی بات ظاہر ہو گئی میں نے ہی اسے پھسلانا چاہا تھا اور وہ سچا ہے',\n",
       " 'پھر جادوگر سجدہ میں گر پڑے کہا ہم ہارون اورموسیٰ کے رب پر ایمان لائے',\n",
       " 'یہ عام طور پر آپ کے دانتوں کو ایک منٹ کے لئے چھوڑ دیا جاتا ہے.',\n",
       " 'ترجمہ: \"اور (اے رسول) ہم نے آپ کی طرف حق کے ساتھ کتاب نازل فرمائی ہے جو سابقہ کتابوں کی تصدیق کرنے والی اور ان کے مضامین کی محافظ ونگران ہے۔\"(سورۃ المائدہ،آیت 48)',\n",
       " 'اس سے تو پتا چلتا ہے کہ عذاب کا سلسلہ موت ہی سے شروع ہوجاتا ہے۔',\n",
       " 'کہ میرا کُل اثاثہ ، لفظ ہیں یہی ، سو تیری نذر ہیں',\n",
       " 'اب امریکہ نے دوبارہ ایسا کیا تو ۔۔۔!',\n",
       " 'مجھے تیری 3 باتیں سمجھ نہیں آتیں',\n",
       " 'صحیح حدیث میں بھی آیا ہے کہ نظر کا لگنا حق ہے اگر کوئی چیز تقدیر ہے سبقت کرنے والی ہوتی تو نظر ہوتی',\n",
       " '8 Responses to جاد اللہ القرآنی',\n",
       " '12 وہ آسمان پر تو ہے نہیں کہ تُو کہے کہ آسمان پر کون ہماری خاطر چڑھے اور اُسکو ہمارے پاس لا کر سُنائے تاکہ ہم اُس پر عمل کریں ؟',\n",
       " 'مجھے اپنے جسم کا یہ حصہ پسند ہے',\n",
       " 'لیکن رب اُس سے ہم کلام ہوا اور کہا، ”تیری سلامتی ہو۔ مت ڈر، تُو نہیں مرے گا۔“',\n",
       " 'فائدہ: انسان موت سے بھاگ نہیں سکتا اسی لیے اللہ تعالیٰ نے فرمایا:',\n",
       " 'اور بیشک ہم نے تم کو سات آیتیں دیں جو دہرائی جاتی ہیں اور عظمت والا قرآن،',\n",
       " '24 پھر بعد جب نوح نیند سے اٹھے اور چھو ٹا بیٹا حام نے جو کیا تھا اس کو معلوم ہوا ۔',\n",
       " 'بیشک اللہ تعالیٰ لوگوں پر فضل و کرم والا ہے لیکن اکثر لوگ شکر گزاری نہیں کرتے۔',\n",
       " 'لکھنے یا لکھنے کے لئے نہیں، یہ سوال ہے.',\n",
       " 'افسوس اس بات کا ہے کہ یہ حملہ نہ تو پہلا ہے نہ ہی آخری.',\n",
       " 'اور ان کے دلوں پر ہم نے پردے ڈال دیئے ہیں کہ وه اسے سمجھیں اور ان کے کانوں میں بوجھ اور جب تو صرف اللہ ہی کا ذکر اس کی توحید کے ساتھ، اس قرآن میں کرتا ہے تو وه روگردانی کرتے پیٹھ پھیر کر بھاگ کھڑے ہوتے ہیں',\n",
       " 'جڑا تھا جن کا خدا کے کلام سے رشتہ',\n",
       " 'پھر میں نے پانی لیا اور اس کے تمام جسم پر انڈیل دیا .',\n",
       " 'خود اپنے آپ چہرے پر تحریر ہو گئے',\n",
       " 'ہاتھ آنے پہ وہ تیور کہ بدی گھبرائے',\n",
       " 'ٹیک اور انڈس فوڈ ۔ چیم کے مجوزہ آغاز کے بارے میں کہا کہ ان دو نئی اکائیوں کاآغاز ایف اینڈ بی پروسیسنگ ٹیکنالوجی اور سارک، افریقہ اور یورو ایشیا کے ملکوں کے ذریعہ کھانوں کے مصالحے کی سپلائی اور کم لاگت میں بھارت کی قوت کی نمائش کرنے کا ایک بہترین موقع ہے۔',\n",
       " 'ایک حسین سجائی ہوئی چھت ہوتی ہے.',\n",
       " 'امریکی حکومت کے ملازمین جو سرکاری کام سے سفر کر رہے ہوں؛ اور',\n",
       " '28 اور اِؔسرئیل کہنے لگا یہ بس ہے کہ میرا بیٹا یُوؔسف اب تک جِیتا ہے ۔ میَں اپنے مرنے سے پیشتر جا کر اُسے دیکھ تو لوُنگا۔',\n",
       " 'میرا 100 $ تحفہ کارڈ ملا:]]]',\n",
       " 'میرے لئے, میں ہوں میں آرٹ اور موسیقی.',\n",
       " 'اور گم گیا ان سے جسے پہلے پوجتے تھے اور سمجھ لیے کہ انہیں کہیں بھاگنے کی جگہ نہیں،',\n",
       " 'طاقتور رہنا چاہیے',\n",
       " 'اٹک لیزر نصب کرنا؟ مدد کرنے کے لئے یہاں کچھ تجاویز ہیں',\n",
       " 'View Full Version : سمجھنے کی کوشش کیجئے',\n",
       " 'چلو کے بارے میں بات کیلے اور جنسی innuendos.',\n",
       " '(۵)جس نے دھوکہ دیا وہ ہماری جماعت سے خارج',\n",
       " 'دیکھو دیکھو کون کہہ رہا ہے',\n",
       " 'یا پھر عقائد کی بنیاد پر ایک دوسرے کو کمتر دکھانے کی کوششوں میں مصروف رہتے ہیں.',\n",
       " 'آپ جانتے ہیں کہ آپ کون ہیں، جلد ہی دیکھیں، اور آپ کا شکریہ.',\n",
       " 'ہر بار ایک اچھا تجربہ رہا تھا.',\n",
       " 'کچھ دنوں میں ٹھیک ہوجائے گی۔',\n",
       " 'توبہ اور استغفار میں کیا فرق ہے ؟ سنئے غامدی صاحب کا جواب',\n",
       " '۶– بے شک مشکل کے ساتھ آسانی بھی ہے۔',\n",
       " 'لڑکی نے کہا کہ وہ اب بھی تنگ ہے',\n",
       " 'جی ہاں, میں آپ کو بتا, and more than a prophet.',\n",
       " 'Two Sided',\n",
       " 'میں اس سے بات کر کے دیکھتا ہوں',\n",
       " 'میں کر سکتا ہوں!',\n",
       " 'کیا تیونس میں پھر عرب بہاریہ آنے والا ہے',\n",
       " 'تاکہ ہم تیری بہت سی تسبیح کریں',\n",
       " 'اعلی ینٹیآکسیڈینٹ پروفائل بھی ان کے ایک طویل شیلف زندگی ہے میں مدد ملتی ہے.',\n",
       " 'جرمنی اور یورپ کے بعض شہروں کا درمیانی فاصلہ (یعنی ایک شہر سے نکلنے اور دوسرے شہر میں داخل ہونے کے سائن بورڈ کی مسافت) ایک سو میٹر سے زیادہ نہیں ہوتا حتی کہ دو شہروں کے بعض مکانات اور سڑکیں تو ایک دوسرے سے متصل ہوتی ہیں، ایسے موارد میں حد ترخص کیسے ہوگی؟',\n",
       " 'تو ہے کہ وہ کون ہیں ہے تو, کہ انہوں نے ان کی زندگی ڈال گی ہے.',\n",
       " 'تعاقب میں خوابوں کے رہتی ہیں اکثر',\n",
       " '*اللّٰہ کی قسم!',\n",
       " \"Frank Flannery، سیاسی صلاحکار اور فینے گئیل's تنظیموں کا سابق ڈائریکٹر اور Strategy[46]\",\n",
       " 'اے علی اس شخص کو مبارک ہو جو تجھ سے محبت کرتا ہے اور تیری تصدیق کرتا ہے',\n",
       " 'مجھ کو احساس ہوا تھا کہ کوئی اور بھی ہے',\n",
       " 'یہ کس نے کس کو آمادہ کیاہے، کچھ نہیں کھلتا',\n",
       " 'بالید ورفعہما عند السلام ) یہ کیا بات ہے کہ میں تم کو سرکش گھوڑوں کی دموں',\n",
       " '[44:45] گنہگار کا کھانا ہے۔',\n",
       " 'حقیقت میں، ہم اصل میں صرف اس وقت موجود ہیں.',\n",
       " 'آن لائن صارفین کے 81٪ بلاگ پر پائی جانے والی معلومات پر اعتماد کرتے ہیں.',\n",
       " 'جی آپ کو تھوڑی سی اور یہاں بہت سی تاخیر ہوچکی ہے۔',\n",
       " 'اگلا کیا وہ غیرجانبدار ہے یا نہیں بجائے یہ دیکھنے کے کہ میں نے سر پر کیا اوڑھ رکھا ہے',\n",
       " 'پھر وہ جلوہ نزدیک ہوا پھر خوب اتر آیا',\n",
       " 'آپ کی زبان کی مہارت کے مالک ہیں کرنے کی ضرورت ہے.',\n",
       " '16بقا صرف اسی کو ہے اور وہ اس نور میں رہتا ہے جس تک کسی کی رسائی نہیں ہو سکتی ہے۔ نہ اسے کسی انسان نے دیکھا اور نہ دیکھ سکتا ہے۔ اس کی عزّت اور سلطنت ابد تک رہے۔ آمین۔',\n",
       " 'اگر معاملہ ایسے ہی تو کیا کریں؟',\n",
       " 'کیا ہم نے ان پر کوئی ایسی دلیل نازل کی ہے کہ اُن کو خدا کے ساتھ شرک کرنا بتاتی ہے',\n",
       " 'بخشش بھی بے حساب، سعادت بھی بے حساب',\n",
       " '17 اگر کو ئی یہ چاہے کہ وہ وہی کرے جو خدا چاہتا ہے تب وہ جان جائے گا کہ میری تعلیمات خدا کی طرف سے ہیں۔وہ لوگ جان جائیں گے کہ یہ تعلیمات میری اپنی نہیں ہیں۔',\n",
       " 'سوائے ان لوگوں کے جنہوں نے اس کے بعد توبہ کر لی اور (اپنی) اصلاح کر لی، تو بیشک اﷲ بڑا بخشنے والا مہربان ہے،(89)',\n",
       " 'میدان چھوڑ چھوڑ کے ہوتے رہے فرار',\n",
       " 'my پسندیدہ song in hsm.',\n",
       " 'حضرت زہرا (س) کا اپنے حق کے لیے مدینہ کے تمام لوگوں سے مدد طلب کرنا:',\n",
       " 'شناسا چہرے',\n",
       " 'اے کافرو! آج تم عذر وبہانہ مت کرو۔ تمہیں صرف تمہارے کرتوت کا بدلہ دیا جارہا ہے۔',\n",
       " '84 فیصد کا کہنا تھا وہ اس سے متفق ہیں',\n",
       " 'اور اعلی ترین قراردادوں اور ہموار ترین فریم کی شرحوں پر اپیکس کنودنتیوں کو کھیلنے کے لئے، آپ اسے بہترین پر چلانے کی ضرورت ہے.',\n",
       " 'اُس پر بھروسہ کرو – اور وہ نجات دینے کا تمام کام کرے گا!',\n",
       " 'چانسلر نے طلبا',\n",
       " 'سندھی مسلم ہاؤسنگ سوسائٹی میں مکانات کی خرید',\n",
       " '“کام میں، ہم 996 کی روح پر زور دیتے ہیں.',\n",
       " 'امید ہے کہ اس یونیفارم ان کے لئے ایک چھوٹا سا ٹھنڈا احساس لے جا سکے.',\n",
       " 'پھر جب ہمارا فرمان آپہنچا (١) ہم نے صالح کو اور ان پر ایمان لانے والوں کو اپنی رحمت سے اسے بھی بچا لیا اور اس دن کی رسوائی سے بھی،',\n",
       " 'سماعت کے بعد',\n",
       " 'حضرت علی رضی اﷲ عنہ یہ کہہ کر رو پڑے اور فرمایا تم کو اﷲ کی قسم دے کر پوچھتا ہوں آل فرعون کا رجل مؤمن افضل تھا یا ابوبکر ؟\"',\n",
       " '(۶۲) پھر ان لوگوں نے ابراہیم علیہ السّلام سے کہا کہ کیا تم نے ہمارے خداؤں کے ساتھ یہ برتاؤ کیا ہے',\n",
       " 'BYOE = اپنا سب کچھ لے آؤ',\n",
       " 'علیہ وسلم ان کی آل اورصحابہ کرام پراپنی رحمتوں کا نزول فرمائے ۔ .',\n",
       " 'اور وہ لوگ کہ جب ان پر چڑھائی ہوتی ہے تو وہ بدلہ لیتے ہیں۔ (39)',\n",
       " '157یہ لوگ ہیں جن پر ان کے رب کی طرف سے مہربانیاں ہیں اور رحمت اور یہی ہدایت پانے والے ہیں',\n",
       " 'حالانکہ خدا خود ان کو مذاق بنائے ہوئے ہے اور انہیںسرکشی میں ڈھیل دیئے ہوئے ہے جو انہیں نظر بھی نہیں آرہی ہے',\n",
       " 'کہا جائے گا کہ اے محمد!',\n",
       " 'تختۂ دار پر چڑھا دیجیے',\n",
       " 'اس آخری وقت میں چھ نصیحتیں تمھیں کرتا ہوں',\n",
       " '\"میں گواہی دیتا ہوں کہ اللہ ایک ہے اور مُحمد \"',\n",
       " 'اور الحمد للہ ہم سب کا عقیدہ ہے کہ قرآں پاک رب کا سچا کلام ہے',\n",
       " '5 چیزیں جو آپ کی پہلی تاریخ پر کے بارے میں بات چیت کرتے ہوئے سے بچنا چاہئے',\n",
       " 'راہل! ”تم اتنا کیوں جھٹلا رہے ہو،کیا ڈر ہے جس کو چھپا رہے ہو“: امیت شاہ',\n",
       " 'اپنے اس فلاں بندے کی مغفرت فرما کیونکہ وہ وضو کرکے سویا ہے۔',\n",
       " 'یقینا صرف خدا ہے کہ ایسا کرنے کے قابل ہے.',\n",
       " \"کیا قتل ہو رہا تھا، مجھے نہیں پتہ. '\",\n",
       " 'بہت خوب اگر اشکال کی مدد سے سمجھایا جائے تو بچوں کے لیے یقینا بہت کار آمد ہے',\n",
       " 'اور اُس عورت سے کہا کہ تیرے گناہ معاف ہوئے۔',\n",
       " 'اس موقع پر وزیراعظم نے صحت کی ابتدائی جانچ کے لئے ڈجیٹل نرو سینٹر کے آغاز پر ایک کتبے کی بھی نقاب کشائی کی ۔',\n",
       " 'میں نے کہا :کیا واقعی!تم نے خود سنی ہے ؟',\n",
       " 'میرے نبی پاک ﷺ کے لیے دل پاک ہے !',\n",
       " 'پھر تم اپنے رب کی کس کس نعمت کو جھٹلاؤ گے؟',\n",
       " 'دی ہی جائے دہن اس کو دمِ ایجاد نہیں',\n",
       " 'اور رعد ا سکی پاکی کے ساتھ ا سکی تعریف کرتا ہے اور سب فرشتے اس کے ڈر سے اور بجلیاں بھیجتا ہے پھر انہیں جس پر چاہتا ہے گرا دیتا ہے اور یہ تو الله کے بارے میں جھگڑتے ہیں حالانکہ وہ بڑی قوت والا ہے',\n",
       " 'وزیراعظم کا دفتر وزیر اعظم نے اترکاشی کے بس حادثے میں ہوئے جانی نقصان پر اظہار تسف کیا، متاثرین کیلئے معاوضے کاا علان نئی دہلی۔24مئی۔وزیراعظم جناب نریندر مودی نے اتراکھنڈ کے علاقے اترکاشی میں ہوئے بس حادثے میں ہوئے جانی نقصان پر گہرے رنج وغم کا اظہار کیا ہے۔',\n",
       " 'ہاں (جو) پہلی بار مرنا (تھا سو مرچکے) اور ہمیں عذاب بھی نہیں ہونے کا',\n",
       " 'اب دُھوپ بھول جاؤ کہ سورج یہاں نہیں',\n",
       " 'اِس کو چھوڑیں تو بھلا دین میں کیا رکھا ہے',\n",
       " 'یا دن تیرے اندازِ صباحت پہ گیا ہے رگ رگ نے سمیٹی ہے تیرے نام کی فریاد',\n",
       " 'پاک فوج کا تاثر کم کرنے کی ناپاک کوشش کی جارہی تھی',\n",
       " 'کیا انہوں نے اللہ کو چھوڑ کر بتوں کو اولیاء بنا لیا ہے، پس اللہ ہی ولی ہے (اسی کے دوست ہی اولیاء ہیں)، اور وہی مُردوں کو زندہ کرتا ہے اور وہی ہر چیز پر بڑا قادر ہے،',\n",
       " 'جنریشن X (1965 سے 1980 تک پیدا ہوا)',\n",
       " 'اگر آپ امریکہ کے گاہکوں کے ساتھ کام کرتے ہیں؟',\n",
       " '516۔ دینے والا (خیرات ) تودوزخ کو جائے گا',\n",
       " 'اور، ہم اس کے بارے میں بہت محتاط رہیں گے.',\n",
       " 'تمہیں صبح کیسی لگی ، مری خواہشوں کے دیار کی',\n",
       " '\\u202bاپنے آقا کے پاس گیا۔\\u202c',\n",
       " 'اگر تم اللہ کو قرض حسن دو گے تو وہ اس کو تمہارے لیے مضاعف کرے گا اور تمہیں بخشے گا اور اللہ قدردان اور بردبار ہے۔',\n",
       " 'یہ کالج نہیں جائے گی”۔ دونوں بڑے بھائی ایک ساتھ بولے۔',\n",
       " 'وہ تو یہی چاہتے ہیں کہ جس طرح وہ خود کافر ہیں (اسی طرح) تم بھی کافر ہو کر (سب) برابر ہوجاؤ تو جب تک وہ خدا کی راہ میں وطن نہ چھوڑ جائیں ان میں سے کسی کو دوست نہ بنانا اگر (ترک وطن کو) قبول نہ کریں تو ان کو پکڑ لو اور جہاں پاؤ قتل کردو اور ان میں سے کسی کو اپنا رفیق اور مددگار نہ بناؤ',\n",
       " 'میں نے صرف کاپی اور چسپاں DBCG سے اور کیا گیا تھا!',\n",
       " 'مقررہ تاریخوں پربلدیاتی انتخابات نہیں ہونگے →',\n",
       " '«سانچہ:Country data Fukuoka Prefecture» سے مربوط صفحات',\n",
       " '’’پھر خداوند نے موسیٰ سے کہا: دیکھو میں نے تجھے فرعون کے لیے خدا ٹھہرایا اور تیرا بھائی ہارون تیرا پیغمبر ہو گا۔‘‘',\n",
       " '“میرا ایک خواب ہے ۔” پر 7 تبصرے کئے گئے ہیں',\n",
       " '18 تین دن گزر جانے کے بعد یوسف نے ان سے کہا، ” میں خدا سے خوف کھاتا ہوں۔ اگر تم اسے کرو گے تو میں تمہیں جینے دوں گا۔',\n",
       " 'سال 2018 دنیا بھر میں قدرتی آفات کی زدمیں رہا',\n",
       " 'کچھ ان کا نام و نسب رہزنوں سے ملتا ہے',\n",
       " 'وہ منطق سمجھ میں نہیں آتا کیونکہ غریب مچھلیوں ان کے گھر کو برقرار رکھنے میں مدد کریں.',\n",
       " 'لیکن دودو ان نتائج کے بارے میں شکست رکھتے ہیں.',\n",
       " 'اسرائیل میں تصادم کے دوران 3',\n",
       " '٭جن افراد کی دوسری انگلی چھوٹی ہے، وہ افراد بس اپنی من مانی کرتے ہیں اور دوسروں کے ساتھ ان کی کوئی ہم آہنگی نہیں ہوتی۔',\n",
       " 'اور نصیحت نہیں حاصل کرتے مگر اولوالالباب۔ البقرہ ۲۶۹۔',\n",
       " 'جس دن آسمان ہوگا جیسی گلی چاندی،',\n",
       " 'تو جب یہ لوگ گواہ نہیں لائے تو لازماً اللہ کے نزدیک یہی لوگ جھوٹے ہیں۔',\n",
       " 'دنیا کے راز.',\n",
       " 'انہی سوچوں میں گم اکثر مجھے تاخیر مارے ہے',\n",
       " '’’کہو کیا حال ہے فیضان میاں؟‘‘',\n",
       " 'محبت میں کامیابی اور پسند کی شادی',\n",
       " 'دو سالوں پر، میں نے ابھی تک میرے کھانے کے ایک گروپ کے ایک کاٹنے یا ڈراپ نہیں چھوڑا ہے.',\n",
       " 'Al-Quran 15/86: کچھ شک نہیں کہ تمہارا پروردگار (سب کچھ) پیدا کرنے والا (اور) جاننے والا ہے',\n",
       " 'دیکھیں ہے کون کون ضرورت نہیں رہی',\n",
       " 'عکس ہے کیا شے، صورت کیا ہے',\n",
       " 'نھیں، خدا کی قسم نھیں، خدا کی قسم نھیں، خدا کی قسم نھیں! [12]',\n",
       " 'کونے کے ارد گرد بورڈ امتحان کے ساتھ, students from…',\n",
       " 'میں بے ہنگام جھولے لے رہا ہوں/',\n",
       " 'یا اﷲ آتھم مر جائے.',\n",
       " 'کلمیکس کنٹرول کا شکریہ، آپ کی جنسی زندگی اصلی برش ملے گی.',\n",
       " '(1) کیا مخلوق ہونے کے لئے دکھائی دینا ضروری ہے؟',\n",
       " 'سے قارئین کرام نے شاید ہمارا نام بھی پڑھا یا سنا نہ ہوگا اور اگر یہ',\n",
       " 'اور رات کی قسم جبکہ وہ (سورج کو) ڈھانک لیتی ہے',\n",
       " 'کہ میرے ماں باپ نے اس شہر میں ایک ایسے عافیت کدے کا انتظام کر لیا تھا۔',\n",
       " 'کیا سیارچے سورج سے اس طرح ٹکراتے ہیں جس طرح وہ سیاروں یا مہتابوں سے ٹکراتے ہیں؟',\n",
       " 'اس کا ٹھکانا ہاویہ ہے',\n",
       " 'ایک دن آئے گا جب انشاء اللہ، ہم ہر حال میں اللہ کی اطاعت کرنے کے لئے کافی مضبوط ہوں گے.',\n",
       " 'تم سے دوری عذاب لگتی ہے',\n",
       " '21 کسی شخص کا ذہن کئی منصوبے بنا تا ہے لیکن صرف خدا وند کا منصوبہ ہی وجود میں آئے گا۔',\n",
       " 'Christmas فلمیں آپ watch every year?',\n",
       " 'مگر صرف ہمراز دیکھ سکتے ہیں.',\n",
       " 'وہ جوڑے کا تیسرا بچہ تھا.',\n",
       " 'جن کا کوئی نام نہیں، وہ لوگ زباں پر آ جاتے ہیں',\n",
       " 'مَیں تم کو پانی سے بپتسمہ دیتا ہوں، لیکن وہ تمہیں روح القدس سے بپتسمہ دے گا۔“',\n",
       " 'زندگی موت سے بھی بدتر ہے',\n",
       " 'ہم کو یہاں ادویات کی قلت کا سامنا ہے.',\n",
       " 'SEO کے لئے آپ کی ویڈیو کی اصلاح کریں .',\n",
       " 'اب یہ نامزدگیاں 31 جنوری 2019 تک ارسال کی جاسکتی ہیں۔',\n",
       " 'اسی بارے میں: ۔ عالمی عدالت انصاف نے کلبھوشن کی پھانسی پر حکم امتناع جاری کردیا',\n",
       " 'اسی عمل سے اس پر جہنم کی آگ حرام ہو جائے گی، یہ بات حد سے تجاوز، اور مبالغہ',\n",
       " 'یہ جو مدد کرنے میں ایک معجزہ کارکن ہے ایک نرس کے طالب علموں NCLEX گزر.',\n",
       " 'بھلا تم ہر اونچی جگہ پر نشان تعمیر کرتے ہو',\n",
       " 'قومِ نوح اور عاد اور ثمود اور جو لوگ ان کے بعد ہوئے (ان) کے دستورِ سزا کی طرح، اور اللہ بندوں پر ہرگز زیادتی نہیں چاہتا،',\n",
       " 'اُس اللہ کے جس نے مجھے بنایا.',\n",
       " 'کسی بھی ٹیکنالوجی کی ضرورت ہے تو، ہم پیشکش کرنا چاہئے.',\n",
       " '’’اور وہ (یہود) یہ (بھی) کہتے ہیں کہ ہمیں (دوزخ کی) آگ ہرگز نہیں چھوئے گی سوائے گنتی کے چند دنوں کے‘‘۔',\n",
       " 'امریکہ سے آمد',\n",
       " 'میری عرض یہ ہے کہ جو انہوں نے اب یہ پڑھ کر بتایاہے…',\n",
       " 'شکایت نہیں کرتا',\n",
       " '(ازروئے ہم نفس) = ہم دم، ہم خیال، اللہ تعالیٰ نے انسان کو تنہا پیدا نہیں کیا۔',\n",
       " 'اور جو باتیں ان کے سینوں میں پوشیدہ ہوتی ہیں اور جو کام وہ ظاہر کرتے ہیں تمہارا پروردگار ان (سب) کو جانتا ہے',\n",
       " 'ایسے ماحول میں ، جہاں ہم استحکام ، پائیدار ترقی اور خوشحالی کی تلاش میں ہیں ، اس تبدیلی کو لانے میں برکس قیادت فیصلہ کن ہو گی ۔',\n",
       " 'اور یہ ان کی ترجیح ہے!',\n",
       " 'اس کا مطلب ہے اگر آپ صرف ایک بار پکڑے گئے ہیں, آپ سے نکال دیا جائے گا.',\n",
       " '1969 میں سیپاس فلم فیسٹیول کا افتتاح کیا گیا ہے.',\n",
       " 'لوگوں کو صحت کی نمائندگی کے طور پر پیمانے پر نمبروں کو دیکھ کر روکنے کی ضرورت ہے.',\n",
       " '184پھر اگر یہ تجھے جھٹلائیں تو تجھ سے پہلے بہت سے رسول جھٹلائے گئے جو نشانیاں اور صحیفے اور روشن کتاب لائے',\n",
       " 'اور اگر ہم انسان کو اپنی جانب سے رحمت کا مزہ چکھاتے ہیں پھر ہم اسے (کسی وجہ سے) اس سے واپس لے لیتے ہیں تو وہ نہایت مایوس (اور) ناشکرگزار ہو جاتا ہےo',\n",
       " 'جو ایک چشمہ ہے۔ جس سے اللہ کے بندے پئیں گے اس کی نہریں نکال لے جائیں گے (جدھر چاہیں)',\n",
       " 'ہم اس نبی کی امت ہیں جس کے ہاتھوں دینِ آدم ؑ اور دینِ ابراہیم ؑ کی تصدیق و تکمیل ہوئی۔',\n",
       " 'رت ہے۔۔۔ خدا پر ایمان کامل رکھ کر آپ اپنی قوتوں کو متحد کریں اور',\n",
       " 'قابل توجہ ہے کہ اہل سنت کے عالم \"عبد اللہ بن موسی\" کہتے ہیں:',\n",
       " 'تم دونوں کمینے ہو، کمینے۔ !“',\n",
       " 'آپ صلی اللہ علیہ وسلم نے فرمایا کہ اپنے وقت پر نماز پڑھنا،',\n",
       " 'میں جان نہیں پائی کیوں، جب مجھے تیری سب سے زیادہ ضرورت ہوتی ہے، تو مجھے چھوڑ جائے گا۔‘‘',\n",
       " 'تو دلی کا ہر پیرو جواں بے تا ب ہو جا ئے',\n",
       " 'میں جاگوں گا کب تک وہ سوئیں گے تا کے',\n",
       " \"Michael won پسندیدہ Soul/R&B Male Artist, پسندیدہ Soul/R&B Album for Off the Wall, and پسندیدہ Soul/R&B Single for the song 'Don't Stop Till' آپ Get Enough'.\",\n",
       " 'ہے منانا اسی خدا کو ہمیں',\n",
       " 'ٓآل سعود کو منیٰ حادثے کے راز فاش ہو جانے پر تشویش ہے',\n",
       " 'اسرائیل شام میں کیا چاہتا ہے؟',\n",
       " '”بھلا دیکھو تو سہی اِس لڑکے کو جو اپنی قوم سے کٹ گیا ہے اور سمجھتا ہے کہ یہ ہم سے بہتر ہے، حالانکہ ہم حج اور سدانت',\n",
       " 'اور ان کو اپنی رحمت سے (بہت سی چیزیں) عنایت کیں۔ اور ان کا ذکر جمیل بلند کیا',\n",
       " 'ایک سنوبورڈ پر آئس دوڑ',\n",
       " '\"نوٹ لے کے بھاگ گیا تو؟”',\n",
       " 'لوگوں کو کما کر کھانا سکھائیں۔رابی پیرزادہ',\n",
       " 'جب بھی ہم حساس معلومات (جیسے کریڈٹ کارڈ کے اعداد و شمار) کو جمع کرتے ہیں تو یہ معلومات محفوظ طریقے سے خفیہ اور ہمیں منتقل کرتی ہے.',\n",
       " 'دس بارہ برس کی یہ وہی بچی ہے لوگو',\n",
       " 'ہم نے اسے صحیح ای میل پر بھیجا ہے جس نے آپ نے لکھا ہے.',\n",
       " 'اور اسی پر موقوف نہیں، جو سربراہان \"مقبولِ عوام\" تھے انہوں نے ملک کے لیے کونسے تیر مار لیے جو ان میں سرخاب کے پر ڈھونڈ ڈھونڈ کر دنیا کو دکھائے جائیں۔۔']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_en_ur_train_dataset[\"ur\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28eb650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target_text column in dataset\n",
    "target_texts = small_en_ur_train_dataset[\"ur\"]  # Replace with the actual column name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd38179",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4cdeb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
      "\n",
      "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-ur.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "final_model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3e4c811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths before padding: [64, 37, 56, 64, 21, 32, 39, 25, 30, 64, 36, 64, 64, 38, 59, 16, 27, 35, 39, 35, 46, 64, 64, 37, 38, 64, 24, 13, 64, 51, 64, 64, 64, 41, 64, 29, 64, 36, 64, 29, 45, 57, 22, 43, 64, 60, 64, 12, 41, 30, 64, 27, 6, 64, 64, 64, 64, 47, 27, 64, 25, 49, 64, 42, 35, 64, 45, 64, 15, 64, 43, 43, 64, 21, 33, 64, 64, 64, 33, 6, 57, 64, 38, 64, 64, 17, 45, 52, 64, 41, 64, 22, 64, 64, 64, 41, 64, 64, 44, 33, 21, 37, 30, 64, 31, 31, 38, 26, 34, 64, 64, 64, 26, 42, 19, 52, 64, 17, 35, 36, 30, 27, 26, 64, 64, 33, 64, 22, 37, 26, 64, 35, 55, 60, 35, 64, 13, 19, 64, 61, 19, 64, 31, 55, 64, 35, 63, 26, 64, 15, 64, 33, 11, 64, 36, 64, 64, 64, 64, 64, 64, 64, 44, 21, 43, 64, 33, 39, 38, 35, 64, 30, 64, 33, 22, 64, 14, 64, 64, 30, 55, 64, 56, 64, 29, 47, 57, 64, 64, 55, 62, 64, 64, 35, 10, 34, 36, 33, 64, 64, 31, 61, 64, 32, 27, 28, 25, 64, 14, 64, 61, 36, 28, 64, 64, 64, 22, 64, 38, 17, 43, 49, 39, 22, 13, 64, 43, 64, 64, 43, 38, 31, 28, 13, 26, 29, 15, 64, 64, 64, 21, 34, 64, 27, 21, 64, 54, 41, 64, 27, 64, 64, 64, 64, 64, 38, 42, 51, 21, 58, 64, 64, 64, 64, 64, 36, 56, 22, 64, 18, 39, 20, 40, 19, 34, 12, 21, 38, 32, 47, 21, 64, 36, 64, 64, 64, 58, 64, 61, 48, 35, 32, 64, 25, 64, 31, 64, 64, 64, 64, 64, 35, 53, 64, 34, 53, 30, 32, 64, 32, 58, 64, 26, 38, 64, 19, 51, 25, 37, 41, 23, 64, 53, 31, 26, 57, 32, 29, 29, 4, 30, 18, 40, 31, 64, 64, 58, 33, 14, 64, 64, 39, 39, 64, 22, 43, 64, 47, 64, 37, 48, 64, 32, 64, 36, 64, 64, 30, 16, 64, 11, 64, 36, 64, 57, 16, 45, 38, 63, 64, 13, 64, 64, 20, 64, 58, 64, 64, 22, 22, 42, 43, 59, 64, 64, 57, 39, 36, 64, 41, 64, 40, 50, 40, 36, 64, 64, 64, 35, 40, 64, 51, 64, 29, 41, 39, 41, 43, 22, 64, 52, 64, 50, 46, 33, 64, 38, 64, 43, 35, 64, 45, 28, 64, 52, 34, 64, 13, 40, 28, 35, 64, 64, 32, 24, 57, 39, 32, 23, 56, 41, 64, 44, 64, 64, 20, 64, 24, 64, 14, 29, 25, 47, 64, 25, 38, 36, 49, 64, 64, 64, 43, 64, 29, 51, 64, 14, 48, 16, 64, 64, 64, 23, 63, 45, 64, 64, 64, 64, 64, 60, 57, 29, 56, 64, 40, 36, 64, 25, 51, 29, 64, 64, 23, 24, 41, 64, 34, 52, 64]\n",
      "Lengths after ensuring consistent length: [64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64]\n"
     ]
    }
   ],
   "source": [
    "# Use the tokenizer to convert each target text to input IDs for the decoder\n",
    "decoder_input_ids_list = [tokenizer(text, return_tensors=\"tf\", max_length=max_target_length, truncation=True)[\"input_ids\"] for text in target_texts]\n",
    "\n",
    "# Find the maximum length among the decoded input IDs\n",
    "max_decoder_length = max(len(ids[0]) for ids in decoder_input_ids_list)\n",
    "\n",
    "# Get the padding token ID from the tokenizer\n",
    "padding_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Ensure all sequences have the same length by truncating or padding\n",
    "decoder_input_ids_padded = tf.keras.preprocessing.sequence.pad_sequences([ids[0] for ids in decoder_input_ids_list], maxlen=max_decoder_length, padding='post', value=padding_token_id)\n",
    "\n",
    "# Print the lengths before padding\n",
    "print(\"Lengths before padding:\", [len(ids[0]) for ids in decoder_input_ids_list])\n",
    "\n",
    "# Print the lengths after ensuring consistent length\n",
    "print(\"Lengths after ensuring consistent length:\", [len(ids) for ids in decoder_input_ids_padded])\n",
    "\n",
    "# Convert the padded input IDs to a TensorFlow tensor\n",
    "decoder_input_ids = tf.constant(decoder_input_ids_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bdcacd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths before padding: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Lengths after ensuring consistent length: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Use the tokenizer to convert each target text to input IDs for the decoder\n",
    "decoder_input_ids_list = [tokenizer(text, return_tensors=\"tf\", max_length=max_target_length, truncation=True)[\"input_ids\"] for text in target_texts]\n",
    "\n",
    "# Find the maximum length among the decoded input IDs\n",
    "max_decoder_length = max(len(ids) for ids in decoder_input_ids_list)\n",
    "\n",
    "# Get the padding token ID from the tokenizer\n",
    "padding_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Ensure all sequences have the same length by truncating or padding\n",
    "decoder_input_ids_padded = tf.keras.preprocessing.sequence.pad_sequences([ids[0] for ids in decoder_input_ids_list], maxlen=max_decoder_length, padding='post', value=padding_token_id)\n",
    "\n",
    "# Print the lengths before padding\n",
    "print(\"Lengths before padding:\", [len(ids) for ids in decoder_input_ids_list])\n",
    "\n",
    "# Print the lengths after ensuring consistent length\n",
    "print(\"Lengths after ensuring consistent length:\", [len(ids) for ids in decoder_input_ids_padded])\n",
    "\n",
    "# Convert the padded input IDs to a TensorFlow tensor\n",
    "decoder_input_ids = tf.constant(decoder_input_ids_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "106a85ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer Padding Value: 62024\n"
     ]
    }
   ],
   "source": [
    "# Check the tokenizer's padding value\n",
    "padding_token_id = tokenizer.pad_token_id\n",
    "print(\"Tokenizer Padding Value:\", padding_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca7aa826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the input shape to match the model's expectation\n",
    "# final_model_input = Input(shape=(max_input_length,))\n",
    "\n",
    "# final_model_input = Input(shape=(max_input_length,), name=\"input_9\")\n",
    "# final_model_input = Input(shape=(max_input_length,), name=\"input_12\")\n",
    "\n",
    "final_model_input = tf.keras.layers.Input(shape=(max_input_length,), name=\"final_model_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0696c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TimeDistributed, Flatten, Input, Dense\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "# Get the predicted output\n",
    "# final_model_output = final_model(final_model_input, decoder_input_ids=decoder_input_ids)\n",
    "\n",
    "# Get model outputs\n",
    "final_model_output = final_model(final_model_input, decoder_input_ids=tokenized_train_datasets['labels'])\n",
    "\n",
    "# Access the logits tensor\n",
    "logits = final_model_output.logits\n",
    "\n",
    "# Print the shape of the logits before flattening\n",
    "print(\"Shape before flattening:\", logits.shape)\n",
    "\n",
    "# Apply TimeDistributed and Flatten\n",
    "flattened_output = TimeDistributed(Flatten())(logits)\n",
    "\n",
    "# Get the size of the Urdu vocabulary using the tokenizer\n",
    "target_vocab_size = len(tokenizer.get_vocab())\n",
    "\n",
    "# Flatten the logits\n",
    "flattened_output = Flatten()(flattened_output)\n",
    "\n",
    "# Define the final dense layer\n",
    "#output_layer = Dense(target_vocab_size, activation='softmax')(flattened_output)\n",
    "\n",
    "# Use Embedding layer for vocabulary projection\n",
    "embedding_dim = 128  # Choose an appropriate embedding dimension\n",
    "# embedding_layer = Embedding(input_dim=target_vocab_size, output_dim=embedding_dim)(flattened_output)\n",
    "# embedding_layer = Embedding(input_dim=target_vocab_size, output_dim=embedding_dim, name=\"output_layer\")(flattened_output)\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=target_vocab_size, output_dim=embedding_dim, name=\"output_layer\")(flattened_output)\n",
    "\n",
    "# Compile the model and perform training\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.fit(train_data, epochs=num_epochs, validation_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "5b6c83c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the model to include CNN and RNN components\n",
    "\n",
    "# model = tf.keras.Model(inputs=[cnn_input, final_model_input], outputs={'embedding_4': embedding_layer}, name=\"en_text_to_urdu_model\")\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Model(inputs=[cnn_input, final_model_input], outputs={'embedding': embedding_layer}, name=\"en_text_to_urdu_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "e5dbac88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of tokenized_train_datasets: ['en', 'ur', 'input_ids', 'attention_mask', 'labels']\n",
      "Keys of tokenized_test_datasets: ['en', 'ur', 'input_ids', 'attention_mask', 'labels']\n"
     ]
    }
   ],
   "source": [
    "# Check the keys of tokenized_train_datasets\n",
    "print(\"Keys of tokenized_train_datasets:\", tokenized_train_datasets.column_names)\n",
    "\n",
    "# Check the keys of tokenized_test_datasets\n",
    "print(\"Keys of tokenized_test_datasets:\", tokenized_test_datasets.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "32b75cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_values = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "b9bd4b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max CNN Input Length: 446\n",
      "Max Final Model Input Length: 312\n",
      "Max Decoder Input IDs Length: 104\n",
      "Max Labels Length: 81\n"
     ]
    }
   ],
   "source": [
    "# Find the maximum lengths\n",
    "max_cnn_input_length = max(len(x['en']) for x in tokenized_train_datasets)\n",
    "max_final_model_input_length = max(len(x['ur']) for x in tokenized_train_datasets)\n",
    "max_decoder_input_ids_length = max(len(x['input_ids']) for x in tokenized_train_datasets)\n",
    "max_labels_length = max(len(x['labels']) for x in tokenized_train_datasets)\n",
    "\n",
    "print(\"Max CNN Input Length:\", max_cnn_input_length)\n",
    "print(\"Max Final Model Input Length:\", max_final_model_input_length)\n",
    "print(\"Max Decoder Input IDs Length:\", max_decoder_input_ids_length)\n",
    "print(\"Max Labels Length:\", max_labels_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "82e1c6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the tokenizer's padding value\n",
    "padding_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Set appropriate padding values\n",
    "padding_values = {\n",
    "    'cnn_input': max_cnn_input_length,\n",
    "    'final_model_input': max_final_model_input_length,\n",
    "    'decoder_input_ids': padding_token_id,\n",
    "    'labels': padding_token_id\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3253bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b116c0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of tokenized_train_datasets: ['en', 'ur', 'input_ids', 'attention_mask', 'labels']\n",
      "Keys of tokenized_test_datasets: ['en', 'ur', 'input_ids', 'attention_mask', 'labels']\n"
     ]
    }
   ],
   "source": [
    "# Update the model to include CNN and RNN components\n",
    "# model = tf.keras.Model(inputs=[cnn_input, final_model_input], outputs={'embedding_4': embedding_layer}, name=\"en_text_to_urdu_model\")\n",
    "model = tf.keras.Model(inputs=[cnn_input, final_model_input], outputs={'embedding': embedding_layer}, name=\"en_text_to_urdu_model\")\n",
    "\n",
    "# Rename the keys in the data dictionary to match the expected input names\n",
    "train_batched_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: ({\n",
    "        'cnn_input': x['en'],\n",
    "        'final_model_input': x['ur'],\n",
    "        'decoder_input_ids': x['input_ids'],\n",
    "        'labels': x['labels']\n",
    "    } for x in tokenized_train_datasets),\n",
    "    output_signature={\n",
    "        'cnn_input': tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "        'final_model_input': tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "        'decoder_input_ids': tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "        'labels': tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "    }\n",
    ").padded_batch(batch_size=16, padding_values=padding_values)\n",
    "\n",
    "# Rename the keys in the data dictionary for the validation dataset as well\n",
    "val_batched_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: ({\n",
    "        'cnn_input': x['en'],\n",
    "        'final_model_input': x['ur'],\n",
    "        'decoder_input_ids': x['input_ids'],\n",
    "        'labels': x['labels']\n",
    "    } for x in tokenized_test_datasets),\n",
    "    output_signature={\n",
    "        'cnn_input': tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "        'final_model_input': tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "        'decoder_input_ids': tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "        'labels': tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "    }\n",
    ").padded_batch(batch_size=16, padding_values=padding_values)\n",
    "\n",
    "# Check the keys of tokenized_train_datasets\n",
    "print(\"Keys of tokenized_train_datasets:\", tokenized_train_datasets.column_names)\n",
    "\n",
    "# Check the keys of tokenized_test_datasets\n",
    "print(\"Keys of tokenized_test_datasets:\", tokenized_test_datasets.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "af25d5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of tokenized_train_datasets: {'cnn_input': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'final_model_input': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'decoder_input_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'labels': TensorSpec(shape=(None, None), dtype=tf.int32, name=None)}\n",
      "Keys of tokenized_test_datasets: {'cnn_input': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'final_model_input': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'decoder_input_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'labels': TensorSpec(shape=(None, None), dtype=tf.int32, name=None)}\n"
     ]
    }
   ],
   "source": [
    "# Rename the keys in the data dictionary to match the expected input names\n",
    "train_batched_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: ({\n",
    "        'cnn_input': x['en'],\n",
    "        'final_model_input': x['ur'],\n",
    "        'decoder_input_ids': x['input_ids'],\n",
    "        'labels': x['labels']\n",
    "    } for x in tokenized_train_datasets),\n",
    "    output_signature={\n",
    "        'cnn_input': tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "        'final_model_input': tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "        'decoder_input_ids': tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "        'labels': tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "    }\n",
    ").padded_batch(batch_size=16, padding_values=padding_values)\n",
    "\n",
    "# Rename the keys in the data dictionary for the validation dataset as well\n",
    "val_batched_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: ({\n",
    "        'cnn_input': x['en'],\n",
    "        'final_model_input': x['ur'],\n",
    "        'decoder_input_ids': x['input_ids'],\n",
    "        'labels': x['labels']\n",
    "    } for x in tokenized_test_datasets),\n",
    "    output_signature={\n",
    "        'cnn_input': tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "        'final_model_input': tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "        'decoder_input_ids': tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "        'labels': tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "    }\n",
    ").padded_batch(batch_size=16, padding_values=padding_values)\n",
    "\n",
    "# Check the keys of tokenized_train_datasets\n",
    "print(\"Keys of tokenized_train_datasets:\", train_batched_dataset.element_spec)\n",
    "\n",
    "# Check the keys of tokenized_test_datasets\n",
    "print(\"Keys of tokenized_test_datasets:\", val_batched_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "3e8d1443",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7a5a62a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"en_text_to_urdu_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_12 (InputLayer)       [(None, 128)]                0         []                            \n",
      "                                                                                                  \n",
      " tf_marian_mt_model_5 (TFMa  TFSeq2SeqLMOutput(loss=Non   7648160   ['input_12[0][0]']            \n",
      " rianMTModel)                e, logits=(500, 1, 62025),   9                                       \n",
      "                              past_key_values=(((500, 8                                           \n",
      "                             , 1, 64),                                                            \n",
      "                              (500, 8, 1, 64),                                                    \n",
      "                              (500, 8, None, 64),                                                 \n",
      "                              (500, 8, None, 64)),                                                \n",
      "                              ((500, 8, 1, 64),                                                   \n",
      "                              (500, 8, 1, 64),                                                    \n",
      "                              (500, 8, None, 64),                                                 \n",
      "                              (500, 8, None, 64)),                                                \n",
      "                              ((500, 8, 1, 64),                                                   \n",
      "                              (500, 8, 1, 64),                                                    \n",
      "                              (500, 8, None, 64),                                                 \n",
      "                              (500, 8, None, 64)),                                                \n",
      "                              ((500, 8, 1, 64),                                                   \n",
      "                              (500, 8, 1, 64),                                                    \n",
      "                              (500, 8, None, 64),                                                 \n",
      "                              (500, 8, None, 64)),                                                \n",
      "                              ((500, 8, 1, 64),                                                   \n",
      "                              (500, 8, 1, 64),                                                    \n",
      "                              (500, 8, None, 64),                                                 \n",
      "                              (500, 8, None, 64)),                                                \n",
      "                              ((500, 8, 1, 64),                                                   \n",
      "                              (500, 8, 1, 64),                                                    \n",
      "                              (500, 8, None, 64),                                                 \n",
      "                              (500, 8, None, 64))),                                               \n",
      "                              decoder_hidden_states=Non                                           \n",
      "                             e, decoder_attentions=None                                           \n",
      "                             , cross_attentions=None, e                                           \n",
      "                             ncoder_last_hidden_state=(                                           \n",
      "                             None, 128, 512),                                                     \n",
      "                              encoder_hidden_states=Non                                           \n",
      "                             e, encoder_attentions=None                                           \n",
      "                             )                                                                    \n",
      "                                                                                                  \n",
      " time_distributed_4 (TimeDi  (500, 1, 62025)              0         ['tf_marian_mt_model_5[0][1]']\n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " flatten_9 (Flatten)         (500, 62025)                 0         ['time_distributed_4[0][0]']  \n",
      "                                                                                                  \n",
      " input_9 (InputLayer)        [(None, 128, 128)]           0         []                            \n",
      "                                                                                                  \n",
      " output_layer (Embedding)    (500, 62025, 128)            7939200   ['flatten_9[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 84420809 (322.04 MB)\n",
      "Trainable params: 84358784 (321.80 MB)\n",
      "Non-trainable params: 62025 (242.29 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a4fb2640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the model to include CNN and RNN components\n",
    "# model = tf.keras.Model(inputs=[cnn_input, final_model_input], outputs={'embedding_4': embedding_layer}, name=\"en_text_to_urdu_model\")\n",
    "\n",
    "model = tf.keras.Model(inputs=[cnn_input, final_model_input], outputs={'embedding': embedding_layer}, name=\"en_text_to_urdu_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ce7314",
   "metadata": {},
   "source": [
    "max_input_length = 64\n",
    "\n",
    "max_target_length = 64\n",
    "\n",
    "batch_size = 8  # Adjust as needed\n",
    "\n",
    "accumulation_steps = 2  # Accumulate gradients over 2 steps\n",
    "\n",
    "optimizer = AdamWeightDecay(learning_rate=5e-5)\n",
    "\n",
    "embedding_dim = 64  # Adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c8742fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MarianConfig {\n",
      "  \"_name_or_path\": \"/tmp/Helsinki-NLP/opus-mt-en-ur\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      62024\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 62024,\n",
      "  \"decoder_vocab_size\": 62025,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 62025,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 62024,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.36.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 62025\n",
      "}\n",
      "\n",
      "Encoder Layers: 6\n",
      "Encoder FFN Dimension: 2048\n",
      "Encoder Attention Heads: 8\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianConfig\n",
    "\n",
    "# Replace 'your_marian_model_name_or_path' with the actual name or path of the Marian model\n",
    "model_checkpoint = 'Helsinki-NLP/opus-mt-en-ur'\n",
    "\n",
    "# Load the model configuration\n",
    "config = MarianConfig.from_pretrained(model_checkpoint)\n",
    "\n",
    "# Print the entire configuration\n",
    "print(config)\n",
    "\n",
    "# Access encoder-related parameters\n",
    "encoder_layers = config.encoder_layers\n",
    "encoder_ffn_dim = config.encoder_ffn_dim\n",
    "encoder_attention_heads = config.encoder_attention_heads\n",
    "\n",
    "# Print the encoder-related parameters\n",
    "print(\"Encoder Layers:\", encoder_layers)\n",
    "print(\"Encoder FFN Dimension:\", encoder_ffn_dim)\n",
    "print(\"Encoder Attention Heads:\", encoder_attention_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "dd39ed4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  en  \\\n",
      "0  And why are the kneeling on your right and on ...   \n",
      "1                       She said: \"She frightens me.   \n",
      "2              We will seek your guidance and input.   \n",
      "3  Can you see the real motive of God the Father ...   \n",
      "4            \"Oh, you're writing historical novels!\"   \n",
      "\n",
      "                                                  ur  \\\n",
      "0  ’’اور آپ ﷺ نے اپنی بائیں ہتھیلی کو بائیں ران ا...   \n",
      "1             کہا اس نے مجھے بس بد دعا سے خوف آتا ہے   \n",
      "2  ہم تجھ سے ہدایت، تقوی، عفت اور بے نیازی طلب کر...   \n",
      "3  ان مثالوں سے آپ خوب سمجھ سکتے ہیں کہ خدا کی اس...   \n",
      "4                             ” آپ داستان لکھتے ہیں!   \n",
      "\n",
      "                                           input_ids  \\\n",
      "0  [57, 1082, 56, 3, 19626, 95, 76, 418, 7, 95, 7...   \n",
      "1   [1598, 108, 52, 82, 24319, 10376, 66, 179, 5, 0]   \n",
      "2         [63, 42, 766, 76, 596, 7, 26, 16350, 5, 0]   \n",
      "3  [2112, 17, 307, 3, 2915, 13784, 10, 71, 3, 219...   \n",
      "4  [82, 9467, 2, 17, 128, 1707, 5395, 13666, 3046...   \n",
      "\n",
      "                                  attention_mask  \\\n",
      "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
      "1                 [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
      "2                 [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
      "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
      "4           [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
      "\n",
      "                                              labels  \n",
      "0  [19977, 346, 88, 20669, 3292, 202, 3573, 752, ...  \n",
      "1  [139, 20, 18, 257, 771, 2426, 1129, 11, 710, 1...  \n",
      "2  [37, 1229, 11, 330, 23, 2757, 23, 73, 12725, 4...  \n",
      "3  [24, 636, 64, 11, 88, 423, 847, 310, 21, 19, 7...  \n",
      "4                    [84, 88, 9397, 6066, 21, 67, 0]  \n"
     ]
    }
   ],
   "source": [
    "# Inspect the first few rows of the training dataset\n",
    "train_df = tokenized_train_datasets.to_pandas()\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba61d5ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "c415673b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of tokenized_train_datasets: {'cnn_input': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'final_model_input': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'decoder_input_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'labels': TensorSpec(shape=(None, None), dtype=tf.int32, name=None)}\n",
      "Keys of tokenized_test_datasets: {'cnn_input': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'final_model_input': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'decoder_input_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'labels': TensorSpec(shape=(None, None), dtype=tf.int32, name=None)}\n"
     ]
    }
   ],
   "source": [
    "# Rename the keys in the data dictionary to match the expected input names\n",
    "train_batched_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: ({\n",
    "        'cnn_input': x['en'],\n",
    "        'final_model_input': x['ur'],\n",
    "        'decoder_input_ids': x['input_ids'],\n",
    "        'labels': x['labels']\n",
    "    } for x in tokenized_train_datasets),\n",
    "    output_signature={\n",
    "        'cnn_input': tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "        'final_model_input': tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "        'decoder_input_ids': tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "        'labels': tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "    }\n",
    ").padded_batch(batch_size=16, padding_values=padding_values)\n",
    "\n",
    "# Rename the keys in the data dictionary for the validation dataset as well\n",
    "val_batched_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: ({\n",
    "        'cnn_input': x['en'],\n",
    "        'final_model_input': x['ur'],\n",
    "        'decoder_input_ids': x['input_ids'],\n",
    "        'labels': x['labels']\n",
    "    } for x in tokenized_test_datasets),\n",
    "    output_signature={\n",
    "        'cnn_input': tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "        'final_model_input': tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "        'decoder_input_ids': tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "        'labels': tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "    }\n",
    ").padded_batch(batch_size=16, padding_values=padding_values)\n",
    "\n",
    "# Check the keys of tokenized_train_datasets\n",
    "print(\"Keys of tokenized_train_datasets:\", train_batched_dataset.element_spec)\n",
    "\n",
    "# Check the keys of tokenized_test_datasets\n",
    "print(\"Keys of tokenized_test_datasets:\", val_batched_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "fa91c8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PaddedBatchDataset element_spec={'cnn_input': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'final_model_input': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'decoder_input_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'labels': TensorSpec(shape=(None, None), dtype=tf.int32, name=None)}>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batched_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "12efeb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PaddedBatchDataset element_spec={'cnn_input': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'final_model_input': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'decoder_input_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'labels': TensorSpec(shape=(None, None), dtype=tf.int32, name=None)}>"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_batched_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "723b8685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "# model.fit(train_batched_dataset, epochs=num_epochs, validation_data=val_batched_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "68f16022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names of train dataset: ['en', 'ur', 'input_ids', 'attention_mask', 'labels']\n",
      "Column names of test dataset: ['en', 'ur', 'input_ids', 'attention_mask', 'labels']\n"
     ]
    }
   ],
   "source": [
    "# Print the column names of the train dataset\n",
    "print(\"Column names of train dataset:\", tokenized_train_datasets.column_names)\n",
    "\n",
    "# Print the column names of the test dataset\n",
    "print(\"Column names of test dataset:\", tokenized_test_datasets.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "3bc6f621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Sequence Lengths: [ 14  10  15  12   8  11  23  13  28  32   6   9  33  31  36  57  41  20\n",
      "  25  16  29  21   4  22  43  34  54  27  17  38   3  40  19  80  42  44\n",
      "  48  53   5  18 104   7  66  26  30  24  51  45  77  47  62  37  35  92\n",
      "  60  39  50  71  55  59]\n",
      "Validation Sequence Lengths: [13 30 49 14 10  8 12  9 18 11 72 15 47 16  4 20 28  5 44  6 23 17  7 32\n",
      " 21 26 19 29 40 42 35 27 37 24 25 34 22 31 92 48 33 38]\n"
     ]
    }
   ],
   "source": [
    "# Check the lengths of sequences in train_df\n",
    "train_sequence_lengths = train_df.apply(lambda x: len(x['input_ids']), axis=1)\n",
    "print(\"Train Sequence Lengths:\", train_sequence_lengths.unique())\n",
    "\n",
    "# Assuming val_df is your validation DataFrame\n",
    "# Check the lengths of sequences in val_df\n",
    "val_sequence_lengths = tokenized_test_datasets.to_pandas().apply(lambda x: len(x['input_ids']), axis=1)\n",
    "print(\"Validation Sequence Lengths:\", val_sequence_lengths.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c86f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the keys in the data dictionary to match the expected input names\n",
    "train_batched_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: ({\n",
    "        'cnn_input': x['input_ids'],\n",
    "        'final_model_input': x['input_ids'],\n",
    "        'decoder_input_ids': x['labels'],\n",
    "        'labels': x['labels']\n",
    "    } for x in tokenized_train_datasets),\n",
    "    output_signature={\n",
    "        'cnn_input': tf.TensorSpec(shape=(None, max_input_length), dtype=tf.int32),\n",
    "        'final_model_input': tf.TensorSpec(shape=(None, max_input_length), dtype=tf.int32),\n",
    "        'decoder_input_ids': tf.TensorSpec(shape=(None, max_target_length), dtype=tf.int32),\n",
    "        'labels': tf.TensorSpec(shape=(None, max_target_length), dtype=tf.int32),\n",
    "    }\n",
    ").padded_batch(batch_size=batch_size, padding_values=padding_values)\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Print the column names of the train dataset\n",
    "print(\"Column names of train dataset:\", tokenized_train_datasets.column_names)\n",
    "\n",
    "# Print the column names of the test dataset\n",
    "print(\"Column names of test dataset:\", tokenized_test_datasets.column_names)\n",
    "\n",
    "# Print the lengths of sequences in train_df\n",
    "train_sequence_lengths = tokenized_train_datasets.to_pandas().apply(lambda x: len(x['input_ids']), axis=1)\n",
    "print(\"Train Sequence Lengths:\", train_sequence_lengths.unique())\n",
    "\n",
    "# Assuming val_df is your validation DataFrame\n",
    "# Print the lengths of sequences in val_df\n",
    "val_sequence_lengths = tokenized_test_datasets.to_pandas().apply(lambda x: len(x['input_ids']), axis=1)\n",
    "print(\"Validation Sequence Lengths:\", val_sequence_lengths.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f182b2a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a128198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d726caef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b202c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5ac39e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2c0d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4619fd23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db41516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "f72656c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'save_pretrained'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[258], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_model_ur/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'save_pretrained'"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"tf_model_ur/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219e8a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce35952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
